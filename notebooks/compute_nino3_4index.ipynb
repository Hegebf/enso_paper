{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Nino3.4 DJF index for each model, and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes Indexes without caring about branch years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from scipy.signal import detrend\n",
    "from matplotlib import pyplot as plt\n",
    "from eofs.xarray import Eof\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import pprint \n",
    "import intake\n",
    "import util \n",
    "\n",
    "# choose where to load data from:\n",
    "load_data_from = 'cloud'\n",
    "#load_data_from = 'glade'\n",
    "\n",
    "if load_data_from == 'glade':\n",
    "    col = intake.open_esm_datastore(\"../catalogs/glade-cmip6.json\")\n",
    "    file = 'available_data.txt'\n",
    "else:\n",
    "    col = intake.open_esm_datastore(\"../catalogs/pangeo-cmip6.json\")\n",
    "    file = 'available_data_cloud.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BCC-CSM2-MR', 'CanESM5', 'CNRM-CM6-1', 'CNRM-ESM2-1', 'E3SM-1-0',\n",
      "       'EC-Earth3', 'EC-Earth3-Veg', 'MIROC-ES2L', 'MIROC6', 'HadGEM3-GC31-LL',\n",
      "       'HadGEM3-GC31-MM', 'UKESM1-0-LL', 'MRI-ESM2-0', 'GISS-E2-1-G', 'CESM2',\n",
      "       'CESM2-WACCM', 'GFDL-ESM4', 'SAM0-UNICON', 'MCM-UA-1-0'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# pick only models with at least 496 yrs in piControl\n",
    "minyrs_control = 496;\n",
    "# models with fewer years often missed future scenarios, so they are not so interesting for us\n",
    "\n",
    "# load table:\n",
    "data_table = pd.read_table(file,index_col=0)\n",
    "models_used = data_table['piControl (yrs)'][data_table['piControl (yrs)'] >= minyrs_control].index\n",
    "print(models_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Possible missing data in cloud: #####\n",
    "# 'E3SM-1-0': historical ensemble members 1 and 4 seems to have some missing years in the end\n",
    "# 'EC-Earth3': historical r24i1p1f1 has some missing years in the end\n",
    "# 'MRI-ESM2-0': ensemble members 2-5 for ssp245 has only 16 years (no more years are available at ESGF)\n",
    "# 'GISS-E2-1-G': 4 of the piControl members contain no data. Same problem on Glade, so probably no data at ESGF either.. \n",
    "# 'CESM2-WACCM': 'ssp370': members 2 and 3 end in year 2055 (also at ESGF)\n",
    "# 'GFDL-ESM4': missing historical in cloud, but this seems to be available on Glade. Glade piControl is missing on of the 100yr files\n",
    "##### For this model, we would have to load piControl from cloud, then historical from Glade, and ssp's from cloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose what model to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MCM-UA-1-0'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models_used[18]\n",
    "#model = models_used[13]\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piControl (ens.mem.)         1\n",
       "historical (ens.mem.)        2\n",
       "ssp126 (ens.mem.)          NaN\n",
       "ssp245 (ens.mem.)            1\n",
       "ssp370 (ens.mem.)            1\n",
       "ssp585 (ens.mem.)            1\n",
       "abrupt-4xCO2 (ens.mem.)      1\n",
       "piControl (yrs)            500\n",
       "historical (yrs)           165\n",
       "ssp126 (yrs)               NaN\n",
       "ssp245 (yrs)                86\n",
       "ssp370 (yrs)                86\n",
       "ssp585 (yrs)                86\n",
       "abrupt-4xCO2 (yrs)         500\n",
       "Name: MCM-UA-1-0, dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_table.loc[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['piControl', 'historical', 'ssp245', 'ssp370', 'ssp585']\n"
     ]
    }
   ],
   "source": [
    "# what experiments does this model have that we want to study?\n",
    "if any(data_table.loc[model][:6] == 'data problem') == False:\n",
    "    exp_list = [exp[:-11] for exp in data_table.loc[model][:6].index if float(data_table.loc[model][:6][exp]) > 0]\n",
    "else:\n",
    "    exp_list = []\n",
    "    for exp in (data_table.loc[model][:6].index):\n",
    "        if  (data_table.loc[model][:6][exp] != 'data problem'):\n",
    "            exp_list = np.append(exp_list, exp[:-11])\n",
    "print(exp_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piControl\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "historical\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "ssp245\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "ssp370\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "ssp585\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'piControl': 'CMIP.UA.MCM-UA-1-0.piControl.Amon.gn',\n",
       " 'historical': 'CMIP.UA.MCM-UA-1-0.historical.Amon.gn',\n",
       " 'ssp245': 'ScenarioMIP.UA.MCM-UA-1-0.ssp245.Amon.gn',\n",
       " 'ssp370': 'ScenarioMIP.UA.MCM-UA-1-0.ssp370.Amon.gn',\n",
       " 'ssp585': 'ScenarioMIP.UA.MCM-UA-1-0.ssp585.Amon.gn'}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_keys = {}; datasets = {}\n",
    "\n",
    "for exp in exp_list:\n",
    "#for exp in [exp_list[1]]:\n",
    "    print(exp)\n",
    "    #cat = col.search(experiment_id = exp, source_id = model, variable_id='ts', table_id='Amon', member_id = 'r1i1p1f1')\n",
    "    cat = col.search(experiment_id = exp, source_id = model, variable_id='ts', table_id='Amon') \n",
    "        \n",
    "    dset_dict = cat.to_dataset_dict(zarr_kwargs={'consolidated': True}, cdf_kwargs={'chunks': {}})\n",
    "    for key in dset_dict.keys():\n",
    "        exp_keys[exp] = key\n",
    "        datasets[key] = dset_dict[key]\n",
    "\n",
    "exp_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piControl\n",
      "noleap calendar\n"
     ]
    }
   ],
   "source": [
    "# load a dataset for manual calendar check:\n",
    "# if other than noleap, above function must be changed\n",
    "exp = exp_list[0]; print(exp)\n",
    "key = exp_keys[exp]\n",
    "exp_datasets = datasets[key]\n",
    "members_sorted = exp_datasets.member_id.sortby(exp_datasets.member_id)\n",
    "\n",
    "ds = exp_datasets.sel(member_id = members_sorted[0])\n",
    "#print(ds.time)\n",
    "\n",
    "#if load_data_from == 'glade'\n",
    "# Time formats for piControl:\n",
    "# 'BCC-CSM2-MR': cftime.DatetimeNoLeap\n",
    "# 'FGOALS-g3': cftime.DatetimeNoLeap # missing files\n",
    "# 'CanESM5': cftime.DatetimeNoLeap # missing ensemble members\n",
    "# 'CNRM-CM6-1': cftime.DatetimeGregorian\n",
    "# 'CNRM-ESM2-1': cftime.DatetimeGregorian # ssp126 have too many time points.\n",
    "# 'E3SM-1-0': cftime.DatetimeNoLeap # missing files\n",
    "# 'EC-Earth3': Timestamp('2259-01-16 12:00:00'), ... , cftime.DatetimeProlepticGregorian(2759,..\n",
    "# 'EC-Earth3-Veg': Timestamp('1852-01-16 12:00:00'), ... , cftime.DatetimeProlepticGregorian(2347,..\n",
    "# 'IPSL-CM6A-LR': Timestamp('1850-01-16 12:00:00'), ... , cftime.DatetimeGregorian(3049,..\n",
    "# 'MIROC-ES2L': Timestamp('1850-01-16 12:00:00'), ... , cftime.DatetimeGregorian(2349,\n",
    "# 'MIROC6': cftime.DatetimeGregorian # code below works, but is not accounting for leap years yet\n",
    "# 'UKESM1-0-LL': cftime.Datetime360Day # code below works, but must be adjusted for 360day calendar\n",
    "# 'MRI-ESM2-0': cftime.DatetimeProlepticGregorian # More data should be requested\n",
    "# 'GISS-E2-1-G': cftime.DatetimeNoLeap # ok, but has no ssp (not in ESGF either)\n",
    "# 'GISS-E2-1-H': cftime.DatetimeNoLeap # ok, but has no ssp (not in ESGF either)\n",
    "# 'CESM2': cftime.DatetimeNoLeap \n",
    "# 'CESM2-WACCM': cftime.DatetimeNoLeap\n",
    "# 'GFDL-CM4': cftime.DatetimeNoLeap\n",
    "# 'SAM0-UNICON': cftime.DatetimeNoLeap\n",
    "if model in ['BCC-CSM2-MR', 'FGOALS-g3', 'CanESM5', 'E3SM-1-0', 'GISS-E2-1-G', 'GISS-E2-1-H', 'CESM2', 'CESM2-WACCM', 'GFDL-CM4', 'SAM0-UNICON', 'GFDL-ESM4', 'MCM-UA-1-0']:\n",
    "    ds_calendar = 'noleap'\n",
    "elif model in ['CNRM-CM6-1', 'CNRM-ESM2-1', 'IPSL-CM6A-LR', 'MIROC-ES2L', 'MIROC6']:\n",
    "    ds_calendar = 'gregorian'\n",
    "elif model in ['EC-Earth3', 'EC-Earth3-Veg', 'MRI-ESM2-0']:\n",
    "    ds_calendar = 'proleptic_gregorian'\n",
    "elif model in ['UKESM1-0-LL', 'HadGEM3-GC31-LL', 'HadGEM3-GC31-MM']:\n",
    "    ds_calendar = '360_day'\n",
    "    \n",
    "print(ds_calendar, 'calendar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_weights(lat_bnds, lon_bnds): \n",
    "    # computes exact area weigths assuming earth is a perfect sphere\n",
    "    lowerlats = np.radians(lat_bnds[:,0]); upperlats = np.radians(lat_bnds[:,1])\n",
    "    difflon = np.radians(np.diff(lon_bnds[0,:])) # if the differences in longitudes are all the same\n",
    "    areaweights = difflon*(np.sin(upperlats) - np.sin(lowerlats));\n",
    "    areaweights /= areaweights.mean()\n",
    "    return areaweights # list of weights, of same dimension as latitude\n",
    "\n",
    "# function copied from: http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "def leap_year(year, calendar='standard'):\n",
    "    \"\"\"Determine if year is a leap year\"\"\"\n",
    "    leap = False\n",
    "    if ((calendar in ['standard', 'gregorian',\n",
    "        'proleptic_gregorian', 'julian']) and\n",
    "        (year % 4 == 0)):\n",
    "        leap = True\n",
    "        if ((calendar == 'proleptic_gregorian') and\n",
    "            (year % 100 == 0) and\n",
    "            (year % 400 != 0)):\n",
    "            leap = False\n",
    "        elif ((calendar in ['standard', 'gregorian']) and\n",
    "                 (year % 100 == 0) and (year % 400 != 0) and\n",
    "                 (year < 1583)):\n",
    "            leap = False\n",
    "    return leap\n",
    "\n",
    "# function copied from: http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "def get_dpm(time, calendar='standard'):\n",
    "    \"\"\"\n",
    "    return a array of days per month corresponding to the months provided in `months`\n",
    "    \"\"\"\n",
    "    month_length = np.zeros(len(time), dtype=np.int)\n",
    "\n",
    "    cal_days = dpm[calendar]\n",
    "\n",
    "    for i, (month, year) in enumerate(zip(time.month, time.year)):\n",
    "        month_length[i] = cal_days[month]\n",
    "        if leap_year(year, calendar=calendar) and month == 2: # the feb-test is missing at the website!\n",
    "            month_length[i] += 1\n",
    "    return month_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspiration taken from: http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "\n",
    "# days per month:\n",
    "dpm = {'noleap': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       'gregorian': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       'proleptic_gregorian': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       '360_day': [0, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]\n",
    "      }\n",
    "\n",
    "def day_weights(ds, chosen_season = 'DJF', calendar = 'noleap'): # new function\n",
    "    month_length = xr.DataArray(get_dpm((ds.time.to_index()), calendar=ds_calendar), coords=[ds.time], name='month_length')\n",
    "    if chosen_season == 'DJF':\n",
    "        season_months = month_length.where(month_length['time.season'] == season)\n",
    "        # repeat last December month, and move it to the beginning\n",
    "        season_months = xr.concat([season_months[-1], season_months], dim = 'time')\n",
    "\n",
    "        norm_by_annual = season_months[1:].groupby('time.year').mean('time') # make annual mean\n",
    "        norm_by_monthly = np.concatenate([np.tile(norm_by_annual.values[i], 12) for i in range(len(norm_by_annual.values))])\n",
    "        # repeat last December month to give it equal length as season_months. Value of last month will not be used.\n",
    "        norm_by_monthly = np.concatenate([norm_by_monthly, [norm_by_monthly[-1]]])\n",
    "\n",
    "        weights = season_months/norm_by_monthly\n",
    "        # make weigths have mean 1 in chosen season for all years\n",
    "        # can be checked by running weights.rolling(min_periods=3, center=True, time=3).mean()\n",
    "        # note that these weights start with a December month\n",
    "    elif chosen_season == 'all':\n",
    "        \n",
    "        ##### This code is not tested yet #####\n",
    "        norm_by_annual = month_length.groupby('time.year').mean('time') # make annual mean\n",
    "        norm_by_monthly = np.concatenate([np.tile(norm_by_annual.values[i], 12) for i in range(len(norm_by_annual.values))])\n",
    "        weights = month_length/norm_by_monthly\n",
    "        # normalized to have mean 1\n",
    "    # if other season wanted, continue developing this if-test\n",
    "    \n",
    "    # NB: normalised weights do not care what numbers are produced for other seasons\n",
    "    return weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latregion = slice(-5,5); lonregion = slice(190, 240) # = 120 W - 170 W\n",
    "# use larger region before regridding, that adds 5 deg to each border:\n",
    "larger_latregion = slice(-10,10); larger_lonregion = slice(185, 245)\n",
    "\n",
    "resolution = 1;\n",
    "ds_out = xr.Dataset({'lon': (['lon'], np.arange(lonregion.start+resolution/2, lonregion.stop+resolution/2, resolution)),\n",
    "                     'lat': (['lat'], np.arange(latregion.start+resolution/2, latregion.stop+resolution/2, resolution))\n",
    "                    }\n",
    "                   )\n",
    "    \n",
    "regr_lat_bnds = np.array([[upper, upper+resolution] for upper in range(latregion.start,latregion.stop)])\n",
    "regr_lon_bnds = np.array([[upper, upper+resolution] for upper in range(lonregion.start,lonregion.stop)])\n",
    "area_w = area_weights(regr_lat_bnds, regr_lon_bnds)\n",
    "\n",
    "season = 'DJF'\n",
    "lastD = {}\n",
    "\n",
    "for exp in exp_list:\n",
    "#for exp in exp_list[:2]:\n",
    "    key = exp_keys[exp]\n",
    "    exp_datasets = datasets[key]\n",
    "    members_sorted = exp_datasets.member_id.sortby(exp_datasets.member_id)\n",
    "    #for member in [members_sorted.values[0]]: # check for first member only\n",
    "    for member in members_sorted.values:\n",
    "        print(exp, member)\n",
    "        ds = exp_datasets.sel(member_id = member)\n",
    "        \n",
    "        # select regional data, perform a regridding, and compute area average\n",
    "        if model == 'MCM-UA-1-0':\n",
    "             ds = ds.rename({'longitude': 'lon','latitude': 'lat'}) \n",
    "        regional_data = ds.ts.sel(lat = larger_latregion, lon = larger_lonregion)\n",
    "        regridder = xe.Regridder(regional_data, ds_out, 'bilinear', reuse_weights = True)\n",
    "        regridded_data = regridder(regional_data)\n",
    "        area_avg = (regridded_data.transpose('time', 'lon', 'lat') * area_w).mean(dim=['lon', 'lat'])\n",
    "            \n",
    "        yrs = int(area_avg.shape[0]/12)\n",
    "        \n",
    "        weights = day_weights(area_avg, chosen_season = season, calendar = ds_calendar)\n",
    "        # double check that weights are 1 for all seasons\n",
    "        meanweights = weights.rolling(min_periods=3, center=True, time=3).mean()\n",
    "        print('years in experiment:', yrs, '    ',  'mean weights all 1?', all(meanweights.dropna(dim = 'time') == 1))\n",
    "        \n",
    "        if exp == 'historical':\n",
    "            # save last december month for each member for use in season mean in first year of ssp exps\n",
    "            lastD[member] = area_avg[-1] \n",
    "            weights = weights[1:] # drop first december month\n",
    "        elif exp == 'piControl':\n",
    "            weights = weights[1:] # drop first december month\n",
    "        elif exp not in ['piControl','historical']: # then it must be future scenario   \n",
    "            area_avg = xr.concat([lastD[member], area_avg], dim = 'time')  \n",
    "            weights = weights.assign_coords(time = area_avg.time)\n",
    "            \n",
    "        # average over season\n",
    "        day_weighted_avg = area_avg*weights\n",
    "        ds_season = day_weighted_avg.where(day_weighted_avg['time.season'] == season) # creates nan in all other months\n",
    "            \n",
    "        ds_season3 = ds_season.rolling(min_periods=3, center=True, time=3).mean()\n",
    "        \n",
    "        if exp not in ['piControl','historical']:\n",
    "            # remove nan-value obtained from inserting last december month from historical\n",
    "            ds_season3 = ds_season3[1:]\n",
    "        seasonmean = ds_season3.groupby('time.year').mean('time') # make annual mean\n",
    "        # no information the first year of piControl and historical, since we are missing the december month before\n",
    "        \n",
    "        # day-weighted rolling 3-months mean for all months (with seasonal variations)\n",
    "        #day_weighted_avg_allyear = area_avg*day_weights(yrs, chosen_season = 'all')\n",
    "        #smoothed_allyear = day_weighted_avg_allyear.rolling(min_periods=3, center=True, time=3).mean()\n",
    "        \n",
    "        colname = [(exp, member)]\n",
    "        \n",
    "        first_member_piControl = 'r1i1p1f1'\n",
    "        if model in ['CNRM-CM6-1', 'CNRM-ESM2-1', 'UKESM1-0-LL', 'MIROC-ES2L']:\n",
    "            first_member_piControl = 'r1i1p1f2'\n",
    "        elif model in ['GISS-E2-1-G']:\n",
    "            first_member_piControl = 'r101i1p1f1'\n",
    "        \n",
    "        if exp == 'piControl' and member == first_member_piControl:\n",
    "            # create dataframe for storing all results and make the piControl years the index\n",
    "            df = pd.DataFrame(seasonmean.values, columns = colname)\n",
    "        else:\n",
    "            df_col = pd.DataFrame(seasonmean.values, columns = colname)\n",
    "            df = pd.merge(df, df_col, left_index=True, right_index=True, how='outer')\n",
    "        \n",
    "df.columns = pd.MultiIndex.from_tuples(df.columns, names=['Experiment','Member'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check values in last December for historical\n",
    "[lastD[member].values for member in lastD.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.min_rows', 165)\n",
    "df.iloc[:165];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check that first and last rows of ssp exps look reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.min_rows', 90)\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "#df['ssp370'].iloc[85:88]\n",
    "df.iloc[85:88]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Processed_data/Nino3_4_DJF/' + model + '_DJF_nino3_4index.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing files\n",
    "\n",
    "#cat = col.search(source_id = model, experiment_id = 'historical', variable_id='ts', table_id='Amon',member_id = 'r5i1p1f1')\n",
    "#cat = col.search(source_id = model, experiment_id = 'historical', variable_id='ts', table_id='Amon')\n",
    "#cat = col.search(source_id = model, experiment_id = 'piControl', variable_id='ts', table_id='Amon')\n",
    "\n",
    "#cat = col.search(source_id = model, experiment_id = 'ssp126', variable_id='ts', table_id='Amon')\n",
    "cat = col.search(source_id = model, experiment_id = 'ssp370', variable_id='ts', table_id='Amon')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar code as above, but for computing 3-month running mean index for all months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piControl r1i1p1f1\n",
      "Reuse existing file: bilinear_8x16_10x50.nc\n",
      "historical r1i1p1f1\n",
      "Reuse existing file: bilinear_8x16_10x50.nc\n",
      "historical r1i1p1f2\n",
      "Reuse existing file: bilinear_8x16_10x50.nc\n",
      "ssp245 r1i1p1f2\n",
      "Reuse existing file: bilinear_8x16_10x50.nc\n",
      "ssp370 r1i1p1f2\n",
      "Reuse existing file: bilinear_8x16_10x50.nc\n",
      "ssp585 r1i1p1f2\n",
      "Reuse existing file: bilinear_8x16_10x50.nc\n"
     ]
    }
   ],
   "source": [
    "latregion = slice(-5,5); lonregion = slice(190, 240) # = 120 W - 170 W\n",
    "# use larger region before regridding, that adds 5 deg to each border:\n",
    "larger_latregion = slice(-10,10); larger_lonregion = slice(185, 245)\n",
    "\n",
    "resolution = 1;\n",
    "ds_out = xr.Dataset({'lon': (['lon'], np.arange(lonregion.start+resolution/2, lonregion.stop+resolution/2, resolution)),\n",
    "                     'lat': (['lat'], np.arange(latregion.start+resolution/2, latregion.stop+resolution/2, resolution))\n",
    "                    }\n",
    "                   )\n",
    "    \n",
    "regr_lat_bnds = np.array([[upper, upper+resolution] for upper in range(latregion.start,latregion.stop)])\n",
    "regr_lon_bnds = np.array([[upper, upper+resolution] for upper in range(lonregion.start,lonregion.stop)])\n",
    "area_w = area_weights(regr_lat_bnds, regr_lon_bnds)\n",
    "\n",
    "season = 'all'\n",
    "lastD = {}; lastW = {}\n",
    "\n",
    "for exp in exp_list:\n",
    "#for exp in exp_list[:2]:\n",
    "    key = exp_keys[exp]\n",
    "    exp_datasets = datasets[key]\n",
    "    members_sorted = exp_datasets.member_id.sortby(exp_datasets.member_id)\n",
    "    #for member in [members_sorted.values[0]]: # check for first member only\n",
    "    for member in members_sorted.values:\n",
    "        print(exp, member)\n",
    "        ds = exp_datasets.sel(member_id = member)\n",
    "        \n",
    "        # select regional data, perform a regridding, and compute area average\n",
    "        if model == 'MCM-UA-1-0':\n",
    "             ds = ds.rename({'longitude': 'lon','latitude': 'lat'}) \n",
    "        regional_data = ds.ts.sel(lat = larger_latregion, lon = larger_lonregion)\n",
    "        regridder = xe.Regridder(regional_data, ds_out, 'bilinear', reuse_weights = True)\n",
    "        regridded_data = regridder(regional_data)\n",
    "        area_avg = (regridded_data.transpose('time', 'lon', 'lat') * area_w).mean(dim=['lon', 'lat'])\n",
    "            \n",
    "        yrs = int(area_avg.shape[0]/12)\n",
    "        weights = day_weights(area_avg, chosen_season = season, calendar = ds_calendar)\n",
    "        \n",
    "        if exp == 'historical':\n",
    "            # save last december month for each member for use in season mean in first year of ssp exps\n",
    "            lastD[member] = area_avg[-1] \n",
    "            lastW[member] = weights[-1]\n",
    "        elif exp not in ['piControl','historical']: # then it must be future scenario   \n",
    "            area_avg = xr.concat([lastD[member], area_avg], dim = 'time')\n",
    "            weights = xr.concat([lastW[member], weights], dim = 'time')\n",
    "            \n",
    "        # average over season with area weights of mean 1 within each year\n",
    "        #day_weighted_avg = area_avg*weights\n",
    "        #ds_season3 = day_weighted_avg.rolling(min_periods=3, center=True, time=3).mean()\n",
    "        \n",
    "        # convert to numpy array for increased computational speed\n",
    "        weights = np.array(weights); area_avg = np.array(area_avg)\n",
    "        # do rolling mean in for-loop, to give weigths a mean of 1 in each season\n",
    "        ds_season3 = np.full(len(area_avg), np.nan)\n",
    "        for t in range(1, len(area_avg)-1):\n",
    "            season_weigths = weights[t-1:t+2]/weights[t-1:t+2].mean();\n",
    "            ds_season3[t] = np.mean(area_avg[t-1:t+2]*season_weigths)\n",
    "        \n",
    "        if exp not in ['piControl','historical']:\n",
    "            # remove nan-value obtained from inserting last december month from historical\n",
    "            ds_season3 = ds_season3[1:]\n",
    "        \n",
    "        colname = [(exp, member)]\n",
    "        \n",
    "        first_member_piControl = 'r1i1p1f1'\n",
    "        if model in ['CNRM-CM6-1', 'CNRM-ESM2-1', 'UKESM1-0-LL', 'MIROC-ES2L']:\n",
    "            first_member_piControl = 'r1i1p1f2'\n",
    "        elif model in ['GISS-E2-1-G']:\n",
    "            first_member_piControl = 'r101i1p1f1'\n",
    "        \n",
    "        if exp == 'piControl' and member == first_member_piControl:\n",
    "            # create dataframe for storing all results and make the piControl years the index\n",
    "            #df = pd.DataFrame(ds_season3.values, columns = colname)\n",
    "            df = pd.DataFrame(ds_season3, columns = colname)\n",
    "        else:\n",
    "            #df_col = pd.DataFrame(ds_season3.values, columns = colname)\n",
    "            df_col = pd.DataFrame(ds_season3, columns = colname)\n",
    "            df = pd.merge(df, df_col, left_index=True, right_index=True, how='outer')\n",
    "        \n",
    "df.columns = pd.MultiIndex.from_tuples(df.columns, names=['Experiment','Member'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th>piControl</th>\n",
       "      <th colspan=\"2\" halign=\"left\">historical</th>\n",
       "      <th>ssp245</th>\n",
       "      <th>ssp370</th>\n",
       "      <th>ssp585</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Member</th>\n",
       "      <th>r1i1p1f1</th>\n",
       "      <th>r1i1p1f1</th>\n",
       "      <th>r1i1p1f2</th>\n",
       "      <th>r1i1p1f2</th>\n",
       "      <th>r1i1p1f2</th>\n",
       "      <th>r1i1p1f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>303.300248</td>\n",
       "      <td>303.343550</td>\n",
       "      <td>303.332455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>300.093754</td>\n",
       "      <td>300.162410</td>\n",
       "      <td>300.214210</td>\n",
       "      <td>302.953274</td>\n",
       "      <td>302.890400</td>\n",
       "      <td>303.161504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>300.433198</td>\n",
       "      <td>300.561534</td>\n",
       "      <td>300.839232</td>\n",
       "      <td>302.894341</td>\n",
       "      <td>302.639719</td>\n",
       "      <td>303.223195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>300.816654</td>\n",
       "      <td>300.813037</td>\n",
       "      <td>301.355935</td>\n",
       "      <td>303.246616</td>\n",
       "      <td>302.786923</td>\n",
       "      <td>303.627882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>300.992538</td>\n",
       "      <td>300.885482</td>\n",
       "      <td>301.601543</td>\n",
       "      <td>303.610254</td>\n",
       "      <td>303.055453</td>\n",
       "      <td>303.982558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Experiment   piControl  historical                  ssp245      ssp370  \\\n",
       "Member        r1i1p1f1    r1i1p1f1    r1i1p1f2    r1i1p1f2    r1i1p1f2   \n",
       "0                  NaN         NaN         NaN  303.300248  303.343550   \n",
       "1           300.093754  300.162410  300.214210  302.953274  302.890400   \n",
       "2           300.433198  300.561534  300.839232  302.894341  302.639719   \n",
       "3           300.816654  300.813037  301.355935  303.246616  302.786923   \n",
       "4           300.992538  300.885482  301.601543  303.610254  303.055453   \n",
       "\n",
       "Experiment      ssp585  \n",
       "Member        r1i1p1f2  \n",
       "0           303.332455  \n",
       "1           303.161504  \n",
       "2           303.223195  \n",
       "3           303.627882  \n",
       "4           303.982558  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th>piControl</th>\n",
       "      <th colspan=\"2\" halign=\"left\">historical</th>\n",
       "      <th>ssp245</th>\n",
       "      <th>ssp370</th>\n",
       "      <th>ssp585</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Member</th>\n",
       "      <th>r1i1p1f1</th>\n",
       "      <th>r1i1p1f1</th>\n",
       "      <th>r1i1p1f2</th>\n",
       "      <th>r1i1p1f2</th>\n",
       "      <th>r1i1p1f2</th>\n",
       "      <th>r1i1p1f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>300.170761</td>\n",
       "      <td>300.204575</td>\n",
       "      <td>300.050828</td>\n",
       "      <td>306.357691</td>\n",
       "      <td>305.488484</td>\n",
       "      <td>305.952746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1031</td>\n",
       "      <td>300.189855</td>\n",
       "      <td>300.412200</td>\n",
       "      <td>300.183992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1032</td>\n",
       "      <td>300.223531</td>\n",
       "      <td>300.464283</td>\n",
       "      <td>300.342781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1033</td>\n",
       "      <td>300.469699</td>\n",
       "      <td>300.635910</td>\n",
       "      <td>300.707880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1034</td>\n",
       "      <td>300.947642</td>\n",
       "      <td>300.856385</td>\n",
       "      <td>301.178004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Experiment   piControl  historical                  ssp245      ssp370  \\\n",
       "Member        r1i1p1f1    r1i1p1f1    r1i1p1f2    r1i1p1f2    r1i1p1f2   \n",
       "1030        300.170761  300.204575  300.050828  306.357691  305.488484   \n",
       "1031        300.189855  300.412200  300.183992         NaN         NaN   \n",
       "1032        300.223531  300.464283  300.342781         NaN         NaN   \n",
       "1033        300.469699  300.635910  300.707880         NaN         NaN   \n",
       "1034        300.947642  300.856385  301.178004         NaN         NaN   \n",
       "\n",
       "Experiment      ssp585  \n",
       "Member        r1i1p1f2  \n",
       "1030        305.952746  \n",
       "1031               NaN  \n",
       "1032               NaN  \n",
       "1033               NaN  \n",
       "1034               NaN  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1030:1035]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save data to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Processed_data/Nino3_4_monthly/' + model + '_nino3_4monthlyindex.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MCM-UA-1-0'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pd.isnull(df['piControl']['r1i1p2f1'])) # nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pd.isnull(df['piControl']['r1i1p2f1']) == False) # values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5410/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMIP6 2019.10a",
   "language": "python",
   "name": "cmip6-201910a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
