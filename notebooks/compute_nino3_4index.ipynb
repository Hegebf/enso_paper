{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Nino3.4 DJF index for each model, and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes Indexes without caring about branch years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from scipy.signal import detrend\n",
    "from matplotlib import pyplot as plt\n",
    "from eofs.xarray import Eof\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import pprint \n",
    "import intake\n",
    "import util \n",
    "\n",
    "# choose where to load data from:\n",
    "load_data_from = 'cloud'\n",
    "#load_data_from = 'glade'\n",
    "\n",
    "if load_data_from == 'glade':\n",
    "    col = intake.open_esm_datastore(\"../catalogs/glade-cmip6.json\")\n",
    "    file = 'available_data.txt'\n",
    "else:\n",
    "    col = intake.open_esm_datastore(\"../catalogs/pangeo-cmip6.json\")\n",
    "    file = 'available_data_cloud.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BCC-CSM2-MR', 'CanESM5', 'CNRM-CM6-1', 'CNRM-ESM2-1', 'E3SM-1-0',\n",
      "       'EC-Earth3', 'EC-Earth3-Veg', 'MIROC-ES2L', 'MIROC6', 'HadGEM3-GC31-LL',\n",
      "       'HadGEM3-GC31-MM', 'UKESM1-0-LL', 'MRI-ESM2-0', 'GISS-E2-1-G', 'CESM2',\n",
      "       'CESM2-WACCM', 'GFDL-ESM4', 'SAM0-UNICON', 'MCM-UA-1-0'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# pick only models with at least 496 yrs in piControl\n",
    "minyrs_control = 496;\n",
    "# models with fewer years often missed future scenarios, so they are not so interesting for us\n",
    "\n",
    "# load table:\n",
    "data_table = pd.read_table(file,index_col=0)\n",
    "models_used = data_table['piControl (yrs)'][data_table['piControl (yrs)'] >= minyrs_control].index\n",
    "print(models_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Possible missing data in cloud: #####\n",
    "# 'E3SM-1-0': historical ensemble members 1 and 4 seems to have some missing years in the end\n",
    "# 'EC-Earth3': historical r24i1p1f1 has some missing years in the end\n",
    "# 'MRI-ESM2-0': ensemble members 2-5 for ssp245 has only 16 years (no more years are available at ESGF)\n",
    "# 'GISS-E2-1-G': 4 of the piControl members contain no data. Same problem on Glade, so probably no data at ESGF either.. \n",
    "# 'CESM2-WACCM': 'ssp370': members 2 and 3 end in year 2055 (also at ESGF)\n",
    "# 'GFDL-ESM4': missing historical in cloud, but this seems to be available on Glade. Glade piControl is missing on of the 100yr files\n",
    "##### For this model, we would have to load piControl from cloud, then historical from Glade, and ssp's from cloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose what model to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CanESM5'"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models_used[1]\n",
    "#model = models_used[13]\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "piControl (ens.mem.)          2\n",
       "historical (ens.mem.)        50\n",
       "ssp126 (ens.mem.)            50\n",
       "ssp245 (ens.mem.)            50\n",
       "ssp370 (ens.mem.)            50\n",
       "ssp585 (ens.mem.)            50\n",
       "abrupt-4xCO2 (ens.mem.)       2\n",
       "piControl (yrs)            1000\n",
       "historical (yrs)            165\n",
       "ssp126 (yrs)                286\n",
       "ssp245 (yrs)                 86\n",
       "ssp370 (yrs)                 86\n",
       "ssp585 (yrs)                286\n",
       "abrupt-4xCO2 (yrs)          151\n",
       "Name: CanESM5, dtype: object"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_table.loc[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['piControl', 'historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n"
     ]
    }
   ],
   "source": [
    "# what experiments does this model have that we want to study?\n",
    "if any(data_table.loc[model][:6] == 'data problem') == False:\n",
    "    exp_list = [exp[:-11] for exp in data_table.loc[model][:6].index if float(data_table.loc[model][:6][exp]) > 0]\n",
    "else:\n",
    "    exp_list = []\n",
    "    for exp in (data_table.loc[model][:6].index):\n",
    "        if  (data_table.loc[model][:6][exp] != 'data problem'):\n",
    "            exp_list = np.append(exp_list, exp[:-11])\n",
    "print(exp_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piControl\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "historical\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "ssp126\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "ssp245\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "ssp370\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n",
      "ssp585\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'piControl': 'CMIP.CCCma.CanESM5.piControl.Amon.gn',\n",
       " 'historical': 'CMIP.CCCma.CanESM5.historical.Amon.gn',\n",
       " 'ssp126': 'ScenarioMIP.CCCma.CanESM5.ssp126.Amon.gn',\n",
       " 'ssp245': 'ScenarioMIP.CCCma.CanESM5.ssp245.Amon.gn',\n",
       " 'ssp370': 'ScenarioMIP.CCCma.CanESM5.ssp370.Amon.gn',\n",
       " 'ssp585': 'ScenarioMIP.CCCma.CanESM5.ssp585.Amon.gn'}"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_keys = {}; datasets = {}\n",
    "\n",
    "for exp in exp_list:\n",
    "#for exp in [exp_list[1]]:\n",
    "    print(exp)\n",
    "    #cat = col.search(experiment_id = exp, source_id = model, variable_id='ts', table_id='Amon', member_id = 'r1i1p1f1')\n",
    "    cat = col.search(experiment_id = exp, source_id = model, variable_id='ts', table_id='Amon') \n",
    "        \n",
    "    dset_dict = cat.to_dataset_dict(zarr_kwargs={'consolidated': True}, cdf_kwargs={'chunks': {}})\n",
    "    for key in dset_dict.keys():\n",
    "        exp_keys[exp] = key\n",
    "        datasets[key] = dset_dict[key]\n",
    "\n",
    "exp_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piControl\n",
      "noleap calendar\n"
     ]
    }
   ],
   "source": [
    "# load a dataset for manual calendar check:\n",
    "# if other than noleap, above function must be changed\n",
    "exp = exp_list[0]; print(exp)\n",
    "key = exp_keys[exp]\n",
    "exp_datasets = datasets[key]\n",
    "members_sorted = exp_datasets.member_id.sortby(exp_datasets.member_id)\n",
    "\n",
    "ds = exp_datasets.sel(member_id = members_sorted[0])\n",
    "#print(ds.time)\n",
    "\n",
    "#if load_data_from == 'glade'\n",
    "# Time formats for piControl:\n",
    "# 'BCC-CSM2-MR': cftime.DatetimeNoLeap\n",
    "# 'FGOALS-g3': cftime.DatetimeNoLeap # missing files\n",
    "# 'CanESM5': cftime.DatetimeNoLeap # missing ensemble members\n",
    "# 'CNRM-CM6-1': cftime.DatetimeGregorian\n",
    "# 'CNRM-ESM2-1': cftime.DatetimeGregorian # ssp126 have too many time points.\n",
    "# 'E3SM-1-0': cftime.DatetimeNoLeap # missing files\n",
    "# 'EC-Earth3': Timestamp('2259-01-16 12:00:00'), ... , cftime.DatetimeProlepticGregorian(2759,..\n",
    "# 'EC-Earth3-Veg': Timestamp('1852-01-16 12:00:00'), ... , cftime.DatetimeProlepticGregorian(2347,..\n",
    "# 'IPSL-CM6A-LR': Timestamp('1850-01-16 12:00:00'), ... , cftime.DatetimeGregorian(3049,..\n",
    "# 'MIROC-ES2L': Timestamp('1850-01-16 12:00:00'), ... , cftime.DatetimeGregorian(2349,\n",
    "# 'MIROC6': cftime.DatetimeGregorian # code below works, but is not accounting for leap years yet\n",
    "# 'UKESM1-0-LL': cftime.Datetime360Day # code below works, but must be adjusted for 360day calendar\n",
    "# 'MRI-ESM2-0': cftime.DatetimeProlepticGregorian # More data should be requested\n",
    "# 'GISS-E2-1-G': cftime.DatetimeNoLeap # ok, but has no ssp (not in ESGF either)\n",
    "# 'GISS-E2-1-H': cftime.DatetimeNoLeap # ok, but has no ssp (not in ESGF either)\n",
    "# 'CESM2': cftime.DatetimeNoLeap \n",
    "# 'CESM2-WACCM': cftime.DatetimeNoLeap\n",
    "# 'GFDL-CM4': cftime.DatetimeNoLeap\n",
    "# 'SAM0-UNICON': cftime.DatetimeNoLeap\n",
    "if model in ['BCC-CSM2-MR', 'FGOALS-g3', 'CanESM5', 'E3SM-1-0', 'GISS-E2-1-G', 'GISS-E2-1-H', 'CESM2', 'CESM2-WACCM', 'GFDL-CM4', 'SAM0-UNICON', 'GFDL-ESM4', 'MCM-UA-1-0']:\n",
    "    ds_calendar = 'noleap'\n",
    "elif model in ['CNRM-CM6-1', 'CNRM-ESM2-1', 'IPSL-CM6A-LR', 'MIROC-ES2L', 'MIROC6']:\n",
    "    ds_calendar = 'gregorian'\n",
    "elif model in ['EC-Earth3', 'EC-Earth3-Veg', 'MRI-ESM2-0']:\n",
    "    ds_calendar = 'proleptic_gregorian'\n",
    "elif model in ['UKESM1-0-LL', 'HadGEM3-GC31-LL', 'HadGEM3-GC31-MM']:\n",
    "    ds_calendar = '360_day'\n",
    "    \n",
    "print(ds_calendar, 'calendar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_weights(lat_bnds, lon_bnds): \n",
    "    # computes exact area weigths assuming earth is a perfect sphere\n",
    "    lowerlats = np.radians(lat_bnds[:,0]); upperlats = np.radians(lat_bnds[:,1])\n",
    "    difflon = np.radians(np.diff(lon_bnds[0,:])) # if the differences in longitudes are all the same\n",
    "    areaweights = difflon*(np.sin(upperlats) - np.sin(lowerlats));\n",
    "    areaweights /= areaweights.mean()\n",
    "    return areaweights # list of weights, of same dimension as latitude\n",
    "\n",
    "# function copied from: http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "def leap_year(year, calendar='standard'):\n",
    "    \"\"\"Determine if year is a leap year\"\"\"\n",
    "    leap = False\n",
    "    if ((calendar in ['standard', 'gregorian',\n",
    "        'proleptic_gregorian', 'julian']) and\n",
    "        (year % 4 == 0)):\n",
    "        leap = True\n",
    "        if ((calendar == 'proleptic_gregorian') and\n",
    "            (year % 100 == 0) and\n",
    "            (year % 400 != 0)):\n",
    "            leap = False\n",
    "        elif ((calendar in ['standard', 'gregorian']) and\n",
    "                 (year % 100 == 0) and (year % 400 != 0) and\n",
    "                 (year < 1583)):\n",
    "            leap = False\n",
    "    return leap\n",
    "\n",
    "# function copied from: http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "def get_dpm(time, calendar='standard'):\n",
    "    \"\"\"\n",
    "    return a array of days per month corresponding to the months provided in `months`\n",
    "    \"\"\"\n",
    "    month_length = np.zeros(len(time), dtype=np.int)\n",
    "\n",
    "    cal_days = dpm[calendar]\n",
    "\n",
    "    for i, (month, year) in enumerate(zip(time.month, time.year)):\n",
    "        month_length[i] = cal_days[month]\n",
    "        if leap_year(year, calendar=calendar) and month == 2: # the feb-test is missing at the website!\n",
    "            month_length[i] += 1\n",
    "    return month_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspiration taken from: http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "\n",
    "# days per month:\n",
    "dpm = {'noleap': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       'gregorian': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       'proleptic_gregorian': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       '360_day': [0, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]\n",
    "      }\n",
    "\n",
    "def day_weights(ds, chosen_season = 'DJF', calendar = 'noleap'): # new function\n",
    "    month_length = xr.DataArray(get_dpm((ds.time.to_index()), calendar=ds_calendar), coords=[ds.time], name='month_length')\n",
    "    if chosen_season == 'DJF':\n",
    "        season_months = month_length.where(month_length['time.season'] == season)\n",
    "        # repeat last December month, and move it to the beginning\n",
    "        season_months = xr.concat([season_months[-1], season_months], dim = 'time')\n",
    "\n",
    "        norm_by_annual = season_months[1:].groupby('time.year').mean('time') # make annual mean\n",
    "        norm_by_monthly = np.concatenate([np.tile(norm_by_annual.values[i], 12) for i in range(len(norm_by_annual.values))])\n",
    "        # repeat last December month to give it equal length as season_months. Value of last month will not be used.\n",
    "        norm_by_monthly = np.concatenate([norm_by_monthly, [norm_by_monthly[-1]]])\n",
    "\n",
    "        weights = season_months/norm_by_monthly\n",
    "        # make weigths have mean 1 in chosen season for all years\n",
    "        # can be checked by running weights.rolling(min_periods=3, center=True, time=3).mean()\n",
    "        # note that these weights start with a December month\n",
    "    elif chosen_season == 'all':\n",
    "        \n",
    "        ##### This code is not tested yet #####\n",
    "        norm_by_annual = month_length.groupby('time.year').mean('time') # make annual mean\n",
    "        norm_by_monthly = np.concatenate([np.tile(norm_by_annual.values[i], 12) for i in range(len(norm_by_annual.values))])\n",
    "        weights = month_length/norm_by_monthly\n",
    "        # normalized to have mean 1\n",
    "    # if other season wanted, continue developing this if-test\n",
    "    \n",
    "    # NB: normalised weights do not care what numbers are produced for other seasons\n",
    "    return weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latregion = slice(-5,5); lonregion = slice(190, 240) # = 120 W - 170 W\n",
    "# use larger region before regridding, that adds 5 deg to each border:\n",
    "larger_latregion = slice(-10,10); larger_lonregion = slice(185, 245)\n",
    "\n",
    "resolution = 1;\n",
    "ds_out = xr.Dataset({'lon': (['lon'], np.arange(lonregion.start+resolution/2, lonregion.stop+resolution/2, resolution)),\n",
    "                     'lat': (['lat'], np.arange(latregion.start+resolution/2, latregion.stop+resolution/2, resolution))\n",
    "                    }\n",
    "                   )\n",
    "    \n",
    "regr_lat_bnds = np.array([[upper, upper+resolution] for upper in range(latregion.start,latregion.stop)])\n",
    "regr_lon_bnds = np.array([[upper, upper+resolution] for upper in range(lonregion.start,lonregion.stop)])\n",
    "area_w = area_weights(regr_lat_bnds, regr_lon_bnds)\n",
    "\n",
    "season = 'DJF'\n",
    "lastD = {}\n",
    "\n",
    "for exp in exp_list:\n",
    "#for exp in exp_list[:2]:\n",
    "    key = exp_keys[exp]\n",
    "    exp_datasets = datasets[key]\n",
    "    members_sorted = exp_datasets.member_id.sortby(exp_datasets.member_id)\n",
    "    #for member in [members_sorted.values[0]]: # check for first member only\n",
    "    for member in members_sorted.values:\n",
    "        print(exp, member)\n",
    "        ds = exp_datasets.sel(member_id = member)\n",
    "        \n",
    "        # select regional data, perform a regridding, and compute area average\n",
    "        if model == 'MCM-UA-1-0':\n",
    "             ds = ds.rename({'longitude': 'lon','latitude': 'lat'}) \n",
    "        regional_data = ds.ts.sel(lat = larger_latregion, lon = larger_lonregion)\n",
    "        regridder = xe.Regridder(regional_data, ds_out, 'bilinear', reuse_weights = True)\n",
    "        regridded_data = regridder(regional_data)\n",
    "        area_avg = (regridded_data.transpose('time', 'lon', 'lat') * area_w).mean(dim=['lon', 'lat'])\n",
    "            \n",
    "        yrs = int(area_avg.shape[0]/12)\n",
    "        \n",
    "        weights = day_weights(area_avg, chosen_season = season, calendar = ds_calendar)\n",
    "        # double check that weights are 1 for all seasons\n",
    "        meanweights = weights.rolling(min_periods=3, center=True, time=3).mean()\n",
    "        print('years in experiment:', yrs, '    ',  'mean weights all 1?', all(meanweights.dropna(dim = 'time') == 1))\n",
    "        \n",
    "        if exp == 'historical':\n",
    "            # save last december month for each member for use in season mean in first year of ssp exps\n",
    "            lastD[member] = area_avg[-1] \n",
    "            weights = weights[1:] # drop first december month\n",
    "        elif exp == 'piControl':\n",
    "            weights = weights[1:] # drop first december month\n",
    "        elif exp not in ['piControl','historical']: # then it must be future scenario   \n",
    "            area_avg = xr.concat([lastD[member], area_avg], dim = 'time')  \n",
    "            weights = weights.assign_coords(time = area_avg.time)\n",
    "            \n",
    "        # average over season\n",
    "        day_weighted_avg = area_avg*weights\n",
    "        ds_season = day_weighted_avg.where(day_weighted_avg['time.season'] == season) # creates nan in all other months\n",
    "            \n",
    "        ds_season3 = ds_season.rolling(min_periods=3, center=True, time=3).mean()\n",
    "        \n",
    "        if exp not in ['piControl','historical']:\n",
    "            # remove nan-value obtained from inserting last december month from historical\n",
    "            ds_season3 = ds_season3[1:]\n",
    "        seasonmean = ds_season3.groupby('time.year').mean('time') # make annual mean\n",
    "        # no information the first year of piControl and historical, since we are missing the december month before\n",
    "        \n",
    "        # day-weighted rolling 3-months mean for all months (with seasonal variations)\n",
    "        #day_weighted_avg_allyear = area_avg*day_weights(yrs, chosen_season = 'all')\n",
    "        #smoothed_allyear = day_weighted_avg_allyear.rolling(min_periods=3, center=True, time=3).mean()\n",
    "        \n",
    "        colname = [(exp, member)]\n",
    "        \n",
    "        first_member_piControl = 'r1i1p1f1'\n",
    "        if model in ['CNRM-CM6-1', 'CNRM-ESM2-1', 'UKESM1-0-LL', 'MIROC-ES2L']:\n",
    "            first_member_piControl = 'r1i1p1f2'\n",
    "        elif model in ['GISS-E2-1-G']:\n",
    "            first_member_piControl = 'r101i1p1f1'\n",
    "        \n",
    "        if exp == 'piControl' and member == first_member_piControl:\n",
    "            # create dataframe for storing all results and make the piControl years the index\n",
    "            df = pd.DataFrame(seasonmean.values, columns = colname)\n",
    "        else:\n",
    "            df_col = pd.DataFrame(seasonmean.values, columns = colname)\n",
    "            df = pd.merge(df, df_col, left_index=True, right_index=True, how='outer')\n",
    "        \n",
    "df.columns = pd.MultiIndex.from_tuples(df.columns, names=['Experiment','Member'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check values in last December for historical\n",
    "[lastD[member].values for member in lastD.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.min_rows', 165)\n",
    "df.iloc[:165];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check that first and last rows of ssp exps look reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.min_rows', 90)\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "#df['ssp370'].iloc[85:88]\n",
    "df.iloc[85:88]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Processed_data/Nino3_4_DJF/' + model + '_DJF_nino3_4index.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing files\n",
    "\n",
    "#cat = col.search(source_id = model, experiment_id = 'historical', variable_id='ts', table_id='Amon',member_id = 'r5i1p1f1')\n",
    "#cat = col.search(source_id = model, experiment_id = 'historical', variable_id='ts', table_id='Amon')\n",
    "#cat = col.search(source_id = model, experiment_id = 'piControl', variable_id='ts', table_id='Amon')\n",
    "\n",
    "#cat = col.search(source_id = model, experiment_id = 'ssp126', variable_id='ts', table_id='Amon')\n",
    "cat = col.search(source_id = model, experiment_id = 'ssp370', variable_id='ts', table_id='Amon')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "360-90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar code as above, but for computing 3-month running mean index for all months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piControl r1i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "piControl r1i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r10i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r10i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r11i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r11i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r12i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r12i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r13i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r13i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r14i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r14i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r15i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r15i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r16i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r16i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r17i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r17i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r18i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r18i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r19i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r19i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r1i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r1i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r20i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r20i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r21i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r21i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r22i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r22i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r23i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r23i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r24i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r24i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r25i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r25i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r2i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r2i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r3i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r3i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r4i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r4i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r5i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r5i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r6i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r6i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r7i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r7i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r8i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r8i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r9i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "historical r9i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r10i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r10i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r11i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r11i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r12i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r12i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r13i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r13i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r14i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r14i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r15i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r15i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r16i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r16i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r17i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r17i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r18i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r18i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r19i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r19i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r1i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r1i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r20i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r20i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r21i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r21i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r22i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r22i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r23i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r23i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r24i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r24i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r25i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r25i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r2i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r2i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r3i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r3i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r4i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r4i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r5i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r5i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r6i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r6i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r7i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r7i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r8i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r8i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r9i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp126 r9i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r10i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r10i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r11i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r11i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r12i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r12i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r13i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r13i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r14i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r14i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r15i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r15i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r16i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r16i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r17i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r17i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r18i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r18i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r19i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r19i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r1i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r1i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r20i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r20i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r21i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r21i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r22i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r22i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r23i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r23i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r24i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r24i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r25i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r25i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r2i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r2i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r3i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r3i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r4i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r4i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r5i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r5i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r6i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r6i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r7i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r7i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r8i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r8i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r9i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp245 r9i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r10i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r10i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r11i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r11i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r12i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r12i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r13i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r13i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r14i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r14i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r15i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r15i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r16i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r16i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r17i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r17i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r18i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r18i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r19i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r19i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r1i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r1i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r20i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r20i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r21i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r21i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r22i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r22i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r23i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r23i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r24i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r24i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r25i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r25i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r2i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r2i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r3i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r3i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r4i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r4i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r5i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r5i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r6i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r6i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r7i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r7i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r8i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r8i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r9i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp370 r9i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r10i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r10i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r11i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r11i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r12i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r12i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r13i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r13i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r14i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r14i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r15i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r15i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r16i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r16i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r17i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r17i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r18i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r18i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r19i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r19i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r1i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r1i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r20i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r20i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r21i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r21i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r22i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r22i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r23i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r23i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r24i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r24i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r25i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r25i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r2i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r2i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r3i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r3i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r4i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r4i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r5i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r5i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r6i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r6i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r7i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r7i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r8i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r8i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r9i1p1f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n",
      "ssp585 r9i1p2f1\n",
      "Reuse existing file: bilinear_8x25_10x60.nc\n"
     ]
    }
   ],
   "source": [
    "# For Nino3.4 region:\n",
    "#latregion = slice(-5,5); lonregion = slice(190, 240) # = 120 W - 170 W\n",
    "# use larger region before regridding, that adds 5 deg to each border:\n",
    "#larger_latregion = slice(-10,10); larger_lonregion = slice(185, 245)\n",
    "\n",
    "# For Nino3 region:\n",
    "latregion = slice(-5,5); lonregion = slice(210, 270) # = 150 W - 90 W\n",
    "larger_latregion = slice(-10,10); larger_lonregion = slice(205, 275)\n",
    "\n",
    "# For warm pool:\n",
    "#latregion = slice(-5,5); lonregion = slice(120, 170)\n",
    "#larger_latregion = slice(-10,10); larger_lonregion = slice(115, 175)\n",
    "\n",
    "\n",
    "resolution = 1;\n",
    "ds_out = xr.Dataset({'lon': (['lon'], np.arange(lonregion.start+resolution/2, lonregion.stop+resolution/2, resolution)),\n",
    "                     'lat': (['lat'], np.arange(latregion.start+resolution/2, latregion.stop+resolution/2, resolution))\n",
    "                    }\n",
    "                   )\n",
    "    \n",
    "regr_lat_bnds = np.array([[upper, upper+resolution] for upper in range(latregion.start,latregion.stop)])\n",
    "regr_lon_bnds = np.array([[upper, upper+resolution] for upper in range(lonregion.start,lonregion.stop)])\n",
    "area_w = area_weights(regr_lat_bnds, regr_lon_bnds)\n",
    "\n",
    "season = 'all'\n",
    "lastD = {}; lastW = {}\n",
    "\n",
    "for exp in exp_list:\n",
    "#for exp in exp_list[:2]:\n",
    "    key = exp_keys[exp]\n",
    "    exp_datasets = datasets[key]\n",
    "    members_sorted = exp_datasets.member_id.sortby(exp_datasets.member_id)\n",
    "    #for member in [members_sorted.values[0]]: # check for first member only\n",
    "    for member in members_sorted.values:\n",
    "        print(exp, member)\n",
    "        ds = exp_datasets.sel(member_id = member)\n",
    "        \n",
    "        # select regional data, perform a regridding, and compute area average\n",
    "        if model == 'MCM-UA-1-0':\n",
    "             ds = ds.rename({'longitude': 'lon','latitude': 'lat'}) \n",
    "        regional_data = ds.ts.sel(lat = larger_latregion, lon = larger_lonregion)\n",
    "        regridder = xe.Regridder(regional_data, ds_out, 'bilinear', reuse_weights = True)\n",
    "        regridded_data = regridder(regional_data)\n",
    "        area_avg = (regridded_data.transpose('time', 'lon', 'lat') * area_w).mean(dim=['lon', 'lat'])\n",
    "            \n",
    "        yrs = int(area_avg.shape[0]/12)\n",
    "        weights = day_weights(area_avg, chosen_season = season, calendar = ds_calendar)\n",
    "        \n",
    "        if exp == 'historical':\n",
    "            # save last december month for each member for use in season mean in first year of ssp exps\n",
    "            lastD[member] = area_avg[-1] \n",
    "            lastW[member] = weights[-1]\n",
    "        elif exp not in ['piControl','historical']: # then it must be future scenario   \n",
    "            area_avg = xr.concat([lastD[member], area_avg], dim = 'time')\n",
    "            weights = xr.concat([lastW[member], weights], dim = 'time')\n",
    "            \n",
    "        # average over season with area weights of mean 1 within each year\n",
    "        #day_weighted_avg = area_avg*weights\n",
    "        #ds_season3 = day_weighted_avg.rolling(min_periods=3, center=True, time=3).mean()\n",
    "        \n",
    "        # convert to numpy array for increased computational speed\n",
    "        weights = np.array(weights); area_avg = np.array(area_avg)\n",
    "        # do rolling mean in for-loop, to give weigths a mean of 1 in each season\n",
    "        ds_season3 = np.full(len(area_avg), np.nan)\n",
    "        for t in range(1, len(area_avg)-1):\n",
    "            season_weigths = weights[t-1:t+2]/weights[t-1:t+2].mean();\n",
    "            ds_season3[t] = np.mean(area_avg[t-1:t+2]*season_weigths)\n",
    "        \n",
    "        if exp not in ['piControl','historical']:\n",
    "            # remove nan-value obtained from inserting last december month from historical\n",
    "            ds_season3 = ds_season3[1:]\n",
    "        \n",
    "        colname = [(exp, member)]\n",
    "        \n",
    "        first_member_piControl = 'r1i1p1f1'\n",
    "        if model in ['CNRM-CM6-1', 'CNRM-ESM2-1', 'UKESM1-0-LL', 'MIROC-ES2L']:\n",
    "            first_member_piControl = 'r1i1p1f2'\n",
    "        elif model in ['GISS-E2-1-G']:\n",
    "            first_member_piControl = 'r101i1p1f1'\n",
    "        \n",
    "        if exp == 'piControl' and member == first_member_piControl:\n",
    "            # create dataframe for storing all results and make the piControl years the index\n",
    "            #df = pd.DataFrame(ds_season3.values, columns = colname)\n",
    "            df = pd.DataFrame(ds_season3, columns = colname)\n",
    "        else:\n",
    "            #df_col = pd.DataFrame(ds_season3.values, columns = colname)\n",
    "            df_col = pd.DataFrame(ds_season3, columns = colname)\n",
    "            df = pd.merge(df, df_col, left_index=True, right_index=True, how='outer')\n",
    "        \n",
    "df.columns = pd.MultiIndex.from_tuples(df.columns, names=['Experiment','Member'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th colspan=\"2\" halign=\"left\">piControl</th>\n",
       "      <th colspan=\"8\" halign=\"left\">historical</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">ssp585</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Member</th>\n",
       "      <th>r1i1p1f1</th>\n",
       "      <th>r1i1p2f1</th>\n",
       "      <th>r10i1p1f1</th>\n",
       "      <th>r10i1p2f1</th>\n",
       "      <th>r11i1p1f1</th>\n",
       "      <th>r11i1p2f1</th>\n",
       "      <th>r12i1p1f1</th>\n",
       "      <th>r12i1p2f1</th>\n",
       "      <th>r13i1p1f1</th>\n",
       "      <th>r13i1p2f1</th>\n",
       "      <th>...</th>\n",
       "      <th>r5i1p1f1</th>\n",
       "      <th>r5i1p2f1</th>\n",
       "      <th>r6i1p1f1</th>\n",
       "      <th>r6i1p2f1</th>\n",
       "      <th>r7i1p1f1</th>\n",
       "      <th>r7i1p2f1</th>\n",
       "      <th>r8i1p1f1</th>\n",
       "      <th>r8i1p2f1</th>\n",
       "      <th>r9i1p1f1</th>\n",
       "      <th>r9i1p2f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>299.282992</td>\n",
       "      <td>302.120728</td>\n",
       "      <td>301.507559</td>\n",
       "      <td>300.438102</td>\n",
       "      <td>298.109310</td>\n",
       "      <td>300.718389</td>\n",
       "      <td>300.488140</td>\n",
       "      <td>299.934215</td>\n",
       "      <td>300.393161</td>\n",
       "      <td>298.660564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>299.483206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.338948</td>\n",
       "      <td>298.914663</td>\n",
       "      <td>298.922094</td>\n",
       "      <td>298.648654</td>\n",
       "      <td>298.643347</td>\n",
       "      <td>297.823198</td>\n",
       "      <td>298.001569</td>\n",
       "      <td>298.619454</td>\n",
       "      <td>...</td>\n",
       "      <td>298.999387</td>\n",
       "      <td>302.215122</td>\n",
       "      <td>301.883938</td>\n",
       "      <td>300.423645</td>\n",
       "      <td>298.207436</td>\n",
       "      <td>300.691426</td>\n",
       "      <td>300.568897</td>\n",
       "      <td>299.901238</td>\n",
       "      <td>299.849570</td>\n",
       "      <td>298.812806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>299.797560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.879809</td>\n",
       "      <td>299.252705</td>\n",
       "      <td>299.124466</td>\n",
       "      <td>298.699237</td>\n",
       "      <td>299.398119</td>\n",
       "      <td>298.328825</td>\n",
       "      <td>298.549503</td>\n",
       "      <td>299.032613</td>\n",
       "      <td>...</td>\n",
       "      <td>299.200974</td>\n",
       "      <td>302.417535</td>\n",
       "      <td>302.443506</td>\n",
       "      <td>300.491972</td>\n",
       "      <td>298.750245</td>\n",
       "      <td>300.690923</td>\n",
       "      <td>300.749243</td>\n",
       "      <td>300.129220</td>\n",
       "      <td>299.518763</td>\n",
       "      <td>299.528370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>300.119882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.287861</td>\n",
       "      <td>299.185485</td>\n",
       "      <td>299.357538</td>\n",
       "      <td>298.464202</td>\n",
       "      <td>299.852782</td>\n",
       "      <td>298.374914</td>\n",
       "      <td>298.877826</td>\n",
       "      <td>299.234873</td>\n",
       "      <td>...</td>\n",
       "      <td>299.418915</td>\n",
       "      <td>302.146307</td>\n",
       "      <td>302.825863</td>\n",
       "      <td>300.619045</td>\n",
       "      <td>298.853218</td>\n",
       "      <td>300.605831</td>\n",
       "      <td>300.864256</td>\n",
       "      <td>300.518081</td>\n",
       "      <td>299.392079</td>\n",
       "      <td>299.902555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>299.957008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.421663</td>\n",
       "      <td>298.720089</td>\n",
       "      <td>299.139509</td>\n",
       "      <td>297.994338</td>\n",
       "      <td>299.691175</td>\n",
       "      <td>298.101750</td>\n",
       "      <td>298.775331</td>\n",
       "      <td>299.202602</td>\n",
       "      <td>...</td>\n",
       "      <td>299.243942</td>\n",
       "      <td>301.492536</td>\n",
       "      <td>302.488620</td>\n",
       "      <td>300.229017</td>\n",
       "      <td>298.937508</td>\n",
       "      <td>300.466137</td>\n",
       "      <td>300.687543</td>\n",
       "      <td>300.510649</td>\n",
       "      <td>299.210952</td>\n",
       "      <td>299.813380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Experiment   piControl           historical                          \\\n",
       "Member        r1i1p1f1 r1i1p2f1   r10i1p1f1   r10i1p2f1   r11i1p1f1   \n",
       "0                  NaN      NaN         NaN         NaN         NaN   \n",
       "1           299.483206      NaN  298.338948  298.914663  298.922094   \n",
       "2           299.797560      NaN  298.879809  299.252705  299.124466   \n",
       "3           300.119882      NaN  299.287861  299.185485  299.357538   \n",
       "4           299.957008      NaN  299.421663  298.720089  299.139509   \n",
       "\n",
       "Experiment                                                              ...  \\\n",
       "Member       r11i1p2f1   r12i1p1f1   r12i1p2f1   r13i1p1f1   r13i1p2f1  ...   \n",
       "0                  NaN         NaN         NaN         NaN         NaN  ...   \n",
       "1           298.648654  298.643347  297.823198  298.001569  298.619454  ...   \n",
       "2           298.699237  299.398119  298.328825  298.549503  299.032613  ...   \n",
       "3           298.464202  299.852782  298.374914  298.877826  299.234873  ...   \n",
       "4           297.994338  299.691175  298.101750  298.775331  299.202602  ...   \n",
       "\n",
       "Experiment      ssp585                                                  \\\n",
       "Member        r5i1p1f1    r5i1p2f1    r6i1p1f1    r6i1p2f1    r7i1p1f1   \n",
       "0           299.282992  302.120728  301.507559  300.438102  298.109310   \n",
       "1           298.999387  302.215122  301.883938  300.423645  298.207436   \n",
       "2           299.200974  302.417535  302.443506  300.491972  298.750245   \n",
       "3           299.418915  302.146307  302.825863  300.619045  298.853218   \n",
       "4           299.243942  301.492536  302.488620  300.229017  298.937508   \n",
       "\n",
       "Experiment                                                              \n",
       "Member        r7i1p2f1    r8i1p1f1    r8i1p2f1    r9i1p1f1    r9i1p2f1  \n",
       "0           300.718389  300.488140  299.934215  300.393161  298.660564  \n",
       "1           300.691426  300.568897  299.901238  299.849570  298.812806  \n",
       "2           300.690923  300.749243  300.129220  299.518763  299.528370  \n",
       "3           300.605831  300.864256  300.518081  299.392079  299.902555  \n",
       "4           300.466137  300.687543  300.510649  299.210952  299.813380  \n",
       "\n",
       "[5 rows x 252 columns]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <th colspan=\"2\" halign=\"left\">piControl</th>\n",
       "      <th colspan=\"8\" halign=\"left\">historical</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">ssp585</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Member</th>\n",
       "      <th>r1i1p1f1</th>\n",
       "      <th>r1i1p2f1</th>\n",
       "      <th>r10i1p1f1</th>\n",
       "      <th>r10i1p2f1</th>\n",
       "      <th>r11i1p1f1</th>\n",
       "      <th>r11i1p2f1</th>\n",
       "      <th>r12i1p1f1</th>\n",
       "      <th>r12i1p2f1</th>\n",
       "      <th>r13i1p1f1</th>\n",
       "      <th>r13i1p2f1</th>\n",
       "      <th>...</th>\n",
       "      <th>r5i1p1f1</th>\n",
       "      <th>r5i1p2f1</th>\n",
       "      <th>r6i1p1f1</th>\n",
       "      <th>r6i1p2f1</th>\n",
       "      <th>r7i1p1f1</th>\n",
       "      <th>r7i1p2f1</th>\n",
       "      <th>r8i1p1f1</th>\n",
       "      <th>r8i1p2f1</th>\n",
       "      <th>r9i1p1f1</th>\n",
       "      <th>r9i1p2f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>298.443334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.552927</td>\n",
       "      <td>297.674645</td>\n",
       "      <td>299.239346</td>\n",
       "      <td>298.508867</td>\n",
       "      <td>298.330829</td>\n",
       "      <td>298.266524</td>\n",
       "      <td>297.896462</td>\n",
       "      <td>297.612276</td>\n",
       "      <td>...</td>\n",
       "      <td>305.166694</td>\n",
       "      <td>304.537309</td>\n",
       "      <td>304.91241</td>\n",
       "      <td>304.211746</td>\n",
       "      <td>304.524855</td>\n",
       "      <td>305.419537</td>\n",
       "      <td>304.37779</td>\n",
       "      <td>303.90211</td>\n",
       "      <td>304.36108</td>\n",
       "      <td>305.494356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1031</td>\n",
       "      <td>298.552103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.864205</td>\n",
       "      <td>298.029111</td>\n",
       "      <td>299.458792</td>\n",
       "      <td>298.829307</td>\n",
       "      <td>298.754675</td>\n",
       "      <td>298.485468</td>\n",
       "      <td>298.182415</td>\n",
       "      <td>297.728785</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1032</td>\n",
       "      <td>298.559203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.991369</td>\n",
       "      <td>298.165990</td>\n",
       "      <td>299.556446</td>\n",
       "      <td>299.116789</td>\n",
       "      <td>298.873488</td>\n",
       "      <td>298.475292</td>\n",
       "      <td>298.496836</td>\n",
       "      <td>297.816912</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1033</td>\n",
       "      <td>298.488184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.284887</td>\n",
       "      <td>298.330638</td>\n",
       "      <td>299.649213</td>\n",
       "      <td>299.411098</td>\n",
       "      <td>299.099812</td>\n",
       "      <td>298.485477</td>\n",
       "      <td>298.859168</td>\n",
       "      <td>297.848942</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1034</td>\n",
       "      <td>298.823871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.807570</td>\n",
       "      <td>298.657024</td>\n",
       "      <td>299.893861</td>\n",
       "      <td>299.808434</td>\n",
       "      <td>299.439569</td>\n",
       "      <td>298.858137</td>\n",
       "      <td>299.313330</td>\n",
       "      <td>298.282950</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Experiment   piControl           historical                          \\\n",
       "Member        r1i1p1f1 r1i1p2f1   r10i1p1f1   r10i1p2f1   r11i1p1f1   \n",
       "1030        298.443334      NaN  298.552927  297.674645  299.239346   \n",
       "1031        298.552103      NaN  298.864205  298.029111  299.458792   \n",
       "1032        298.559203      NaN  298.991369  298.165990  299.556446   \n",
       "1033        298.488184      NaN  299.284887  298.330638  299.649213   \n",
       "1034        298.823871      NaN  299.807570  298.657024  299.893861   \n",
       "\n",
       "Experiment                                                              ...  \\\n",
       "Member       r11i1p2f1   r12i1p1f1   r12i1p2f1   r13i1p1f1   r13i1p2f1  ...   \n",
       "1030        298.508867  298.330829  298.266524  297.896462  297.612276  ...   \n",
       "1031        298.829307  298.754675  298.485468  298.182415  297.728785  ...   \n",
       "1032        299.116789  298.873488  298.475292  298.496836  297.816912  ...   \n",
       "1033        299.411098  299.099812  298.485477  298.859168  297.848942  ...   \n",
       "1034        299.808434  299.439569  298.858137  299.313330  298.282950  ...   \n",
       "\n",
       "Experiment      ssp585                                                 \\\n",
       "Member        r5i1p1f1    r5i1p2f1   r6i1p1f1    r6i1p2f1    r7i1p1f1   \n",
       "1030        305.166694  304.537309  304.91241  304.211746  304.524855   \n",
       "1031               NaN         NaN        NaN         NaN         NaN   \n",
       "1032               NaN         NaN        NaN         NaN         NaN   \n",
       "1033               NaN         NaN        NaN         NaN         NaN   \n",
       "1034               NaN         NaN        NaN         NaN         NaN   \n",
       "\n",
       "Experiment                                                           \n",
       "Member        r7i1p2f1   r8i1p1f1   r8i1p2f1   r9i1p1f1    r9i1p2f1  \n",
       "1030        305.419537  304.37779  303.90211  304.36108  305.494356  \n",
       "1031               NaN        NaN        NaN        NaN         NaN  \n",
       "1032               NaN        NaN        NaN        NaN         NaN  \n",
       "1033               NaN        NaN        NaN        NaN         NaN  \n",
       "1034               NaN        NaN        NaN        NaN         NaN  \n",
       "\n",
       "[5 rows x 252 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1030:1035]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save data to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('../Processed_data/Nino3_monthly/' + model + '_nino3_monthlyindex.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CanESM5'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pd.isnull(df['piControl']['r1i1p2f1'])) # nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pd.isnull(df['piControl']['r1i1p2f1']) == False) # values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5410/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMIP6 2019.10a",
   "language": "python",
   "name": "cmip6-201910a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
