{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSO diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "from eofs.xarray import Eof\n",
    "import intake\n",
    "import cartopy.crs as ccrs\n",
    "from scipy.interpolate import LSQUnivariateSpline\n",
    "from scipy.stats import skew\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.signal import detrend\n",
    "\n",
    "# models with future scenarios:\n",
    "models = ['BCC-CSM2-MR', 'CanESM5', 'CNRM-CM6-1', 'CNRM-ESM2-1', 'MIROC-ES2L', \n",
    "          'MIROC6', 'UKESM1-0-LL', 'MRI-ESM2-0',  'CESM2', 'CESM2-WACCM', 'MCM-UA-1-0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose where to load data from:\n",
    "load_data_from = 'cloud'\n",
    "#load_data_from = 'glade'\n",
    "\n",
    "if load_data_from == 'glade':\n",
    "    col = intake.open_esm_datastore(\"../catalogs/glade-cmip6.json\")\n",
    "else:\n",
    "    col_url = \"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\"\n",
    "    col = intake.open_esm_datastore(col_url)\n",
    "    #col = intake.open_esm_datastore(\"../catalogs/pangeo-cmip6.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_weights(lat_bnds, lon_bnds): \n",
    "    # computes exact area weigths assuming earth is a perfect sphere\n",
    "    lowerlats = np.radians(lat_bnds[:,0]); upperlats = np.radians(lat_bnds[:,1])\n",
    "    difflon = np.radians(np.diff(lon_bnds[0,:])) # if the differences in longitudes are all the same\n",
    "    areaweights = difflon*(np.sin(upperlats) - np.sin(lowerlats));\n",
    "    areaweights /= areaweights.mean()\n",
    "    return areaweights # list of weights, of same dimension as latitude\n",
    "\n",
    "def numerical_midmonths(xdata):\n",
    "    # converts xarray monthly time data to numpy array with numerical values\n",
    "    # for use in functions that cannot use xarray times as input\n",
    "    midmonths = [int(str(xdata[i])[:4]) + 0.5/12 + int(str(xdata[i])[5:7])/12 for i in range(xdata.shape[0])]\n",
    "    return np.array(midmonths)\n",
    "\n",
    "\n",
    "def cub_spl_monthly_detrending3D(xarray, axis=0):\n",
    "    # detrending by cubic splines, \n",
    "    # specifically written for monthly mean ts data ranging from jan 1850 to dec 2100\n",
    "    xdata = xarray.time.values; ydata = xarray.values # time, lat, lon\n",
    "    dims = list(np.shape(ydata)); axisdim = dims[axis]; dims.pop(axis)\n",
    "    times = numerical_midmonths(xdata)\n",
    "    \n",
    "    internal_knots = [1850 + (2014-1850)/2, 2014]\n",
    "    detr_data = np.full((axisdim, dims[0], dims[1]), np.nan)\n",
    "    for y in range(dims[0]):\n",
    "        for x in range(dims[1]):\n",
    "            gridp_data = ydata[:,y,x]\n",
    "            spl = LSQUnivariateSpline(times, gridp_data, internal_knots)\n",
    "            detr_data[:,y,x] = gridp_data - spl(times)    \n",
    "            \n",
    "    # convert back to xarray:\n",
    "    detr_xarray = xr.DataArray(detr_data, coords={'time': xarray.time, 'lat': xarray.lat, 'lon': xarray.lon},\n",
    "                               dims=['time', 'lat', 'lon'])\n",
    "    detr_xarray = detr_xarray.to_dataset(name = 'detrended_ts')\n",
    "    return detr_xarray\n",
    "\n",
    "def sel_member(model): # finds members chosen for historical and ssp experiments\n",
    "    if model in ['BCC-CSM2-MR', 'CanESM5', 'MIROC6', 'MRI-ESM2-0', 'CESM2-WACCM']:\n",
    "        chosen_member = 'r1i1p1f1'\n",
    "    elif model in ['MIROC-ES2L', 'CNRM-CM6-1','MCM-UA-1-0', 'UKESM1-0-LL']:\n",
    "        chosen_member = 'r1i1p1f2'\n",
    "    elif model in ['CNRM-ESM2-1']:\n",
    "        chosen_member = 'r2i1p1f2'\n",
    "    elif model in ['CESM2']:\n",
    "        chosen_member = 'r4i1p1f1'\n",
    "    return chosen_member\n",
    "\n",
    "def picontrol_member(model): # finds members chosen for piControl\n",
    "    if model in ['BCC-CSM2-MR', 'CanESM5', 'MIROC6', 'MRI-ESM2-0', 'MCM-UA-1-0', 'CESM2', 'CESM2-WACCM']:\n",
    "        chosen_member = 'r1i1p1f1'\n",
    "    elif model in ['MIROC-ES2L', 'CNRM-CM6-1', 'UKESM1-0-LL', 'CNRM-ESM2-1']:\n",
    "        chosen_member = 'r1i1p1f2'\n",
    "    return chosen_member\n",
    "\n",
    "def eof_sign(array):\n",
    "    testpoint = array.sel(lat = 0.5, lon = 175.5)\n",
    "    if testpoint < 0:\n",
    "        sign = -1\n",
    "    else:\n",
    "        sign = 1\n",
    "    return sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # use larger region before regridding, that adds 5 deg to each border:\n",
    "latregion = slice(-15,15); lonregion = slice(140, 280) # = 140 E - 80 W\n",
    "larger_latregion = slice(-20,20); larger_lonregion = slice(135, 285)\n",
    "resolution = 1;\n",
    "ds_out = xr.Dataset({'lon': (['lon'], np.arange(lonregion.start+resolution/2, lonregion.stop+resolution/2, resolution)),\n",
    "                     'lat': (['lat'], np.arange(latregion.start+resolution/2, latregion.stop+resolution/2, resolution))\n",
    "                    }\n",
    "                   )\n",
    "regr_lat_bnds = np.array([[upper, upper+resolution] for upper in range(latregion.start,latregion.stop)])\n",
    "regr_lon_bnds = np.array([[upper, upper+resolution] for upper in range(lonregion.start,lonregion.stop)])\n",
    "area_w = area_weights(regr_lat_bnds, regr_lon_bnds)\n",
    "\n",
    "# choose a model:\n",
    "for model in models:\n",
    "    \n",
    "    #### load data ####\n",
    "    exp_list = ['piControl', 'historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "    exp_keys = {}; datasets = {}\n",
    "    for exp in exp_list:\n",
    "        print(exp)\n",
    "        if exp == 'piControl':\n",
    "            member = picontrol_member(model)\n",
    "        else:\n",
    "            member = sel_member(model)\n",
    "        cat = col.search(experiment_id = exp, source_id = model, variable_id='ts', table_id='Amon', member_id = member)\n",
    "        dset_dict = cat.to_dataset_dict(zarr_kwargs={'consolidated': True}, cdf_kwargs={'chunks': {}})\n",
    "        for key in dset_dict.keys():\n",
    "            exp_keys[exp] = key\n",
    "            datasets[key] = dset_dict[key]\n",
    "    \n",
    "    if model == 'MCM-UA-1-0': \n",
    "        exp_list = ['piControl', 'ssp245', 'ssp370', 'ssp585']\n",
    "    else:\n",
    "        exp_list = ['piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "\n",
    "    #### detrend data ####\n",
    "    anomalies = {}\n",
    "    for exp in exp_list:\n",
    "        if exp in exp_keys:\n",
    "            print(model, exp)\n",
    "\n",
    "            key = exp_keys[exp]\n",
    "            if exp == 'piControl':\n",
    "                member = picontrol_member(model)\n",
    "                ds = datasets[key].sel(member_id = member)\n",
    "                if model == 'MCM-UA-1-0':\n",
    "                    ds = ds.rename({'longitude': 'lon','latitude': 'lat'})\n",
    "\n",
    "                regional_data = ds.ts.sel(lat = larger_latregion, lon = larger_lonregion)\n",
    "                regridder = xe.Regridder(regional_data, ds_out, 'bilinear', reuse_weights = True)\n",
    "                regridded_data = regridder(regional_data)\n",
    "\n",
    "                # linear detrending for first 500 years:\n",
    "                ds_detr = xr.apply_ufunc(detrend, regridded_data[:500*12], kwargs={'axis': 0}, dask = 'allowed')\n",
    "            else:\n",
    "                member = sel_member(model)\n",
    "                hist_ds = datasets[exp_keys['historical']].sel(member_id = member)\n",
    "                ds = datasets[key].sel(member_id = member)\n",
    "                # concatenate and make sure dataset stops in year 2100:\n",
    "                ds = xr.concat([hist_ds, ds], dim = 'time').isel(time=slice(0,3012))\n",
    "                # concatenate historical and ssp, where the historical part is only\n",
    "                # used to get a better trend estimate in ssp period\n",
    "                if model == 'MCM-UA-1-0':\n",
    "                    ds = ds.rename({'longitude': 'lon','latitude': 'lat'})\n",
    "                regional_data = ds.ts.sel(lat = larger_latregion, lon = larger_lonregion)\n",
    "                regridder = xe.Regridder(regional_data, ds_out, 'bilinear', reuse_weights = True)\n",
    "                regridded_data = regridder(regional_data) \n",
    "                # apply cubic spline detrending at every point:\n",
    "                ds_detr = cub_spl_monthly_detrending3D(regridded_data, axis=0)\n",
    "                # use only ssp time period from now on:\n",
    "                ds_detr = ds_detr.isel(time=slice(1980,3012))\n",
    "\n",
    "            # deseasonalise\n",
    "            ts_clim = ds_detr.groupby('time.month').mean(dim='time')\n",
    "            ts_anom = ds_detr.groupby('time.month') - ts_clim\n",
    "            anomalies[exp] = ts_anom\n",
    "            \n",
    "    #### do EOF analysis ####    \n",
    "    # for piControl\n",
    "    data = anomalies['piControl'].transpose('time', 'lon', 'lat')\n",
    "    solver = Eof(data, weights=np.sqrt(area_w))\n",
    "    eofs = solver.eofs(neofs=2)\n",
    "    pcs = solver.pcs(npcs=2)\n",
    "    variance_fractions = solver.varianceFraction(neigs=2)\n",
    "    \n",
    "    # project fields from other experiments onto piControl EOFs\n",
    "    for exp in exp_list[1:]:\n",
    "        proj_data = anomalies[exp].detrended_ts.transpose('time', 'lon', 'lat')\n",
    "        pseudo_pcs = solver.projectField(proj_data, neofs=2)\n",
    "        pseudo_pcs = pseudo_pcs.to_dataset(name = model + '_' + exp + '_pseudo_pcs')\n",
    "        if model == models[0] and exp == exp_list[1]:\n",
    "            all_pseudo_pcs = pseudo_pcs\n",
    "            ssp_time_coord = pseudo_pcs.time\n",
    "        else:\n",
    "            pseudo_pcs = pseudo_pcs.assign_coords(time = ssp_time_coord)\n",
    "            all_pseudo_pcs = xr.merge([all_pseudo_pcs, pseudo_pcs])\n",
    "    \n",
    "    # include model name in variable name, and merge xarrays\n",
    "    variance_fractions = variance_fractions.to_dataset(name = model + '_variance_fractions')\n",
    "    eofs = eofs.to_dataset(name = model + '_eofs')\n",
    "    pcs = pcs.to_dataset(name = model + '_pcs')\n",
    "    \n",
    "    if model in models[1:]: # then xarray already exists that we can merge with\n",
    "        all_variance_fractions = xr.merge([all_variance_fractions, variance_fractions])\n",
    "        all_eofs = xr.merge([all_eofs, eofs])\n",
    "        # convert time axes of all pcs to the same values as the first model\n",
    "        # In that way the final dataset takes up less space\n",
    "        pcs = pcs.assign_coords(time = fixed_time_coord[:len(pcs.time)])\n",
    "        all_pcs = xr.merge([all_pcs, pcs])\n",
    "    else: # create xarrays\n",
    "        all_variance_fractions = variance_fractions\n",
    "        all_eofs = eofs; all_pcs = pcs;\n",
    "        fixed_time_coord = pcs.time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save files to netcdf:\n",
    "\n",
    "#all_eofs.to_netcdf('../Processed_data/eof_data/piControl_2eofs.nc')\n",
    "#all_pcs.to_netcdf('../Processed_data/eof_data/piControl_2pcs.nc')\n",
    "#all_variance_fractions.to_netcdf('../Processed_data/eof_data/piControl_2variance_fractions.nc')\n",
    "#all_pseudo_pcs.to_netcdf('../Processed_data/eof_data/ssp_pseudo_pcs.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load previously saved netcdf files\n",
    "all_eofs = xr.open_dataset('../Processed_data/eof_data/piControl_2eofs.nc')\n",
    "all_pcs = xr.open_dataset('../Processed_data/eof_data/piControl_2pcs.nc')\n",
    "all_variance_fractions = xr.open_dataset('../Processed_data/eof_data/piControl_2variance_fractions.nc')\n",
    "all_pseudo_pcs = xr.open_dataset('../Processed_data/eof_data/ssp_pseudo_pcs.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the first two EOFs\n",
    "\n",
    "Signs are chosen such that the patterns look like in Cai et al.\n",
    "\n",
    "Whenever the sign is changed for an EOF, it is also changed for the PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "maxval = 1.2; step = 0.1\n",
    "data_crs = ccrs.PlateCarree(central_longitude=180.0)\n",
    "\n",
    "for model in models:\n",
    "    var = model + '_eofs'; var_frac = model + '_variance_fractions'\n",
    "    eof1 = all_eofs[var].sel(mode=0); var_frac1 = all_variance_fractions[var_frac].sel(mode=0).values\n",
    "    eof2 = all_eofs[var].sel(mode=1); var_frac2 = all_variance_fractions[var_frac].sel(mode=1).values\n",
    "\n",
    "    var2 = model + '_pcs'\n",
    "    pc1 = all_pcs[var2].sel(mode=0)\n",
    "    pc2 = all_pcs[var2].sel(mode=1)\n",
    "    \n",
    "    # make consistent signs:\n",
    "    sign1 = eof_sign(eof1); sign2 = eof_sign(eof2)\n",
    "    eof1 *= sign1; eof2 *= sign2\n",
    "    pc1 *= sign1; pc2 *= sign2\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols = 2, figsize = [20,3], subplot_kw={'projection': data_crs})\n",
    "    cs0 = ax[0].contourf(all_eofs.lon, all_eofs.lat, (eof1*pc1.std()).transpose(), np.arange(-maxval,maxval+step,step), cmap = 'bwr',extend='both', transform=ccrs.PlateCarree())\n",
    "    cs1 = ax[1].contourf(all_eofs.lon, all_eofs.lat, (eof2*pc2.std()).transpose(), np.arange(-maxval,maxval+step,step), cmap = 'bwr',extend='both', transform=ccrs.PlateCarree())\n",
    "    for i in [0,1]:\n",
    "        ax[i].coastlines(color='gray')\n",
    "    cbar = fig.colorbar(cs1, ax = ax.ravel().tolist(), orientation=\"vertical\")\n",
    "    cbar.set_label('Temperature anomaly', fontsize = 14)\n",
    "    cbar.ax.tick_params(labelsize = 14)\n",
    "    \n",
    "    ax[0].set_title(model + ' piControl EOF1, variance fraction = ' + str(np.round(var_frac1,2)))\n",
    "    ax[1].set_title(model + ' piControl EOF2, variance fraction = ' + str(np.round(var_frac2,2)))\n",
    "    \n",
    "    plt.setp(ax, xticks = np.arange(150, 280, 30)-180, xticklabels = ['150°E', '180°W', '150°W', '120°W', '90°W'])\n",
    "    plt.setp(ax, yticks = [-10, 0, 10], yticklabels = ['10°S', '0', '10°N'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot corresponding principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    \n",
    "    var = model + '_eofs';\n",
    "    eof1 = all_eofs[var].sel(mode=0)\n",
    "    eof2 = all_eofs[var].sel(mode=1)\n",
    "\n",
    "    var2 = model + '_pcs'\n",
    "    pc1 = all_pcs[var2].sel(mode=0)\n",
    "    pc2 = all_pcs[var2].sel(mode=1)\n",
    "    \n",
    "    # make consistent signs:\n",
    "    sign1 = eof_sign(eof1); sign2 = eof_sign(eof2)\n",
    "    eof1 *= sign1; eof2 *= sign2\n",
    "    pc1 *= sign1; pc2 *= sign2\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols = 2, figsize = [18,5])\n",
    "    \n",
    "    ax[0].plot(pc1[:100*12]/pc1.std())\n",
    "    ax[1].plot(pc2[:100*12]/pc2.std())\n",
    "    \n",
    "    ax[0].set_title(model + ' piControl PC1')\n",
    "    ax[1].set_title(model + ' piControl PC2')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter-plots of principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pc1 = pc1/pc1.std(); n_pc2 = pc2/pc2.std()\n",
    "eindex = (n_pc1 - n_pc2)/np.sqrt(2)\n",
    "eindex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_spread(x):\n",
    "    seg_length = 86*12; overlap = seg_length - 30*12;\n",
    "    starttimes = np.arange(0,len(x)-seg_length+1,seg_length - overlap)\n",
    "    segment_std_list = np.full(len(starttimes), np.nan)\n",
    "    for (i,k) in enumerate(starttimes):\n",
    "        segment = x[k:k+seg_length]; segment_std_list[i] = segment.std()\n",
    "    \n",
    "    return [segment_std_list.min(), segment_std_list.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save also information for use in later plots\n",
    "\n",
    "alphas = {}\n",
    "eindex_stds = {}; cindex_stds = {}; \n",
    "cindex_controlstdspread = {}; eindex_controlstdspread = {};\n",
    "e_skewness = {}; c_skewness = {}\n",
    "\n",
    "for model in models:\n",
    "    alphas[model] = {}; eindex_stds[model] = {}; cindex_stds[model] = {}\n",
    "    e_skewness[model] = {}; c_skewness[model] = {}; \n",
    "    cindex_controlstdspread[model] = {}; eindex_controlstdspread[model] = {};\n",
    "    \n",
    "    var = model + '_eofs';\n",
    "    eof1 = all_eofs[var].sel(mode=0)\n",
    "    eof2 = all_eofs[var].sel(mode=1)\n",
    "\n",
    "    var2 = model + '_pcs'\n",
    "    pc1 = all_pcs[var2].sel(mode=0).dropna(dim='time').values\n",
    "    pc2 = all_pcs[var2].sel(mode=1).dropna(dim='time').values\n",
    "    \n",
    "    # make consistent signs:\n",
    "    sign1 = eof_sign(eof1); sign2 = eof_sign(eof2)\n",
    "    eof1 *= sign1; eof2 *= sign2\n",
    "    pc1 *= sign1; pc2 *= sign2\n",
    "    \n",
    "    n_pc1 = pc1/pc1.std(); n_pc2 = pc2/pc2.std()\n",
    "    eindex = (n_pc1 - n_pc2)/np.sqrt(2); eindex_stds[model]['piControl'] = np.std(eindex)\n",
    "    cindex = (n_pc1 + n_pc2)/np.sqrt(2); cindex_stds[model]['piControl'] = np.std(cindex)\n",
    "    c_skewness[model]['piControl'] = skew(cindex); e_skewness[model]['piControl'] = skew(eindex)\n",
    "    \n",
    "    cindex_controlstdspread[model] = std_spread(cindex)\n",
    "    eindex_controlstdspread[model] = std_spread(eindex)\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols = 5, figsize = [20,4])\n",
    "    ax[0].scatter(n_pc1, n_pc2, s = 1)\n",
    "    ax[0].set_title(model + ' piControl')\n",
    "    \n",
    "    # quadratic fit\n",
    "    #x = pc1.dropna(dim='time').values; y = pc2.dropna(dim='time').values\n",
    "    #x = x/np.std(x); y = y/np.std(y); x2= np.arange(min(x),max(x),0.01)\n",
    "    x = n_pc1; y = n_pc2; x2= np.arange(min(x),max(x),0.01)\n",
    "    p2 = np.polyfit(x, y, 2)\n",
    "    #print('alpha = ', p2[0])\n",
    "    qfit = np.polyval(p2, x2)\n",
    "    ax[0].plot(x2, qfit, color = \"black\", linewidth = 2)\n",
    "    ax[0].text(0.5, 0.95, 'alpha = ' + str(np.round(p2[0],3)), fontsize = 14, horizontalalignment='center', verticalalignment='center', transform=ax[0].transAxes);\n",
    "    alphas[model]['piControl'] = p2[0] \n",
    "    if model == 'MCM-UA-1-0': \n",
    "        exp_list = ['ssp245', 'ssp370', 'ssp585']\n",
    "    else:\n",
    "        exp_list = ['ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "    \n",
    "    for (i,exp) in enumerate(exp_list):\n",
    "        var = model + '_' + exp + '_pseudo_pcs'\n",
    "        ppc1 = sign1*all_pseudo_pcs[var].sel(mode=0)\n",
    "        ppc2 = sign2*all_pseudo_pcs[var].sel(mode=1)\n",
    "        n_pc1 = ppc1/pc1.std(); n_pc2 = ppc2/pc2.std()\n",
    "        eindex = (n_pc1 - n_pc2)/np.sqrt(2); eindex_stds[model][exp] = np.std(eindex); \n",
    "        cindex = (n_pc1 + n_pc2)/np.sqrt(2); cindex_stds[model][exp] = np.std(cindex);\n",
    "        c_skewness[model][exp] = skew(cindex); e_skewness[model][exp] = skew(eindex)\n",
    "        \n",
    "        x = n_pc1; y = n_pc2; \n",
    "        x2 = np.arange(min(x), max(x), 0.01)\n",
    "        p2 = np.polyfit(x, y, 2)\n",
    "        qfit = np.polyval(p2, x2)\n",
    "        alphas[model][exp] = p2[0]\n",
    "        \n",
    "        if model == 'MCM-UA-1-0':\n",
    "            ax[i+2].scatter(x, y, s = 1)\n",
    "            ax[i+2].set_title(model + ' ' + exp)\n",
    "            ax[i+2].plot(x2, qfit, color = \"black\", linewidth = 2)\n",
    "            ax[i+2].text(0.5, 0.95, 'alpha = ' + str(np.round(p2[0],3)), fontsize = 14, horizontalalignment='center', verticalalignment='center', transform=ax[i+2].transAxes);\n",
    "        else:    \n",
    "            ax[i+1].scatter(x, y, s = 1)\n",
    "            ax[i+1].set_title(model + ' ' + exp)\n",
    "            ax[i+1].plot(x2, qfit, color = \"black\", linewidth = 2)\n",
    "            ax[i+1].text(0.5, 0.95, 'alpha = ' + str(np.round(p2[0],3)), fontsize = 14, horizontalalignment='center', verticalalignment='center', transform=ax[i+1].transAxes);\n",
    "     \n",
    "    for axis in ax:\n",
    "        axis.set_xlabel('pc1')\n",
    "        axis.set_ylabel('pc2')\n",
    "        axis.set_xlim(-4, 4)\n",
    "        axis.set_ylim(-4, 4)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change of e-index and c-index std\n",
    "fig, ax = plt.subplots(nrows = 2, figsize = [16,8])\n",
    "# define x-coordiates and colors for each experiment\n",
    "x = {}\n",
    "colors = ['black', 'blue', 'purple', 'red', 'green']\n",
    "color_dict = {}\n",
    "delta_x = 0.15\n",
    "explist = ['piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "\n",
    "control_alphas = [alphas[model]['piControl'] for model in models]\n",
    "sorted_models = [x for _,x in sorted(zip(np.abs(control_alphas),models))]\n",
    "\n",
    "for ind,exp in enumerate(explist):\n",
    "    x[exp] = np.arange(len(sorted_models)) + 1 + delta_x*ind\n",
    "    color_dict[exp] = colors[ind]\n",
    "    \n",
    "for (k, model) in enumerate(sorted_models):\n",
    "    if model == 'MCM-UA-1-0': \n",
    "        exp_list = ['ssp245', 'ssp370', 'ssp585']\n",
    "    else:\n",
    "        exp_list = ['ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "    \n",
    "    for (i,exp) in enumerate(exp_list):\n",
    "\n",
    "        e_std = eindex_stds[model][exp] - eindex_stds[model]['piControl']\n",
    "        c_std = cindex_stds[model][exp] - cindex_stds[model]['piControl']\n",
    "        ax[0].axvline(x['piControl'][k]+0.8, color='lightgray')\n",
    "        ax[1].axvline(x['piControl'][k]+0.8, color='lightgray')\n",
    "        \n",
    "        if k == 0:\n",
    "            # then define labels for experiments\n",
    "            ax[0].bar(x[exp][k]-0.065, e_std, width = 0.12, bottom = 1, color=color_dict[exp], label = exp)\n",
    "            ax[1].bar(x[exp][k]-0.065, c_std, width = 0.12, bottom = 1, color=color_dict[exp], label = exp)\n",
    "        else: \n",
    "            ax[0].bar(x[exp][k]-0.065, e_std, width = 0.12, bottom = 1, color=color_dict[exp])\n",
    "            ax[1].bar(x[exp][k]-0.065, c_std, width = 0.12, bottom = 1, color=color_dict[exp])\n",
    "            \n",
    "        if i == 0:\n",
    "            c_spread = cindex_controlstdspread[model]; e_spread = eindex_controlstdspread[model];\n",
    "            ax[0].fill_between([x['piControl'][k]-0.1, x['piControl'][k] + 0.7], e_spread[0], e_spread[1], color = \"lightgray\")\n",
    "            ax[1].fill_between([x['piControl'][k]-0.1, x['piControl'][k] + 0.7], c_spread[0], c_spread[1], color = \"lightgray\")\n",
    "        \n",
    "        if model == 'MCM-UA-1-0': \n",
    "            i += 1     \n",
    "        ax[1].text(x['piControl'][k]-0.1+i/8, 1.7-i/20, str(np.round(alphas[model][exp],3)), color=color_dict[exp], fontsize = 12, verticalalignment='center')\n",
    "    ax[1].text(x['piControl'][k]+0.03, 1.45, str(np.round(alphas[model]['piControl'],3)), color='black', fontsize = 14, verticalalignment='center')\n",
    "for axis in ax:\n",
    "    axis.tick_params(axis='both',labelsize=14)\n",
    "    axis.set_xlim(0.8, 11.8)\n",
    "    axis.plot([0.8, 11.8], [1, 1], color = \"black\")\n",
    "    axis.set_ylim(0.7, 1.5)\n",
    "    axis.set_xticklabels([])\n",
    "    \n",
    "ax[0].set_ylabel('E-index std', fontsize = 14)   \n",
    "ax[1].set_ylabel('C-index std', fontsize = 14)  \n",
    "ax[0].legend(loc=(0.005,0.52), fontsize = 14);\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.xticks(x['piControl']+0.25, sorted_models, rotation=25);\n",
    "plt.text(-0.05, 0.95, 'a', fontweight = 'bold', fontsize = 16, horizontalalignment='center', verticalalignment='center', transform=ax[0].transAxes);\n",
    "plt.text(-0.05, 0.95, 'b', fontweight = 'bold', fontsize = 16, horizontalalignment='center', verticalalignment='center', transform=ax[1].transAxes);\n",
    "\n",
    "#plt.savefig('../Figures/Figure3.png', format='png', dpi=300, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha vs skewness of E-index and C-index (piControl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols = 2, figsize = [16,4])\n",
    "\n",
    "e_skew = {}; c_skew = {}\n",
    "for model in models:\n",
    "    var = model + '_eofs';\n",
    "    eof1 = all_eofs[var].sel(mode=0)\n",
    "    eof2 = all_eofs[var].sel(mode=1)\n",
    "\n",
    "    var2 = model + '_pcs'\n",
    "    pc1 = all_pcs[var2].sel(mode=0).dropna(dim='time').values\n",
    "    pc2 = all_pcs[var2].sel(mode=1).dropna(dim='time').values\n",
    "    \n",
    "    # make consistent signs:\n",
    "    sign1 = eof_sign(eof1); sign2 = eof_sign(eof2)\n",
    "    eof1 *= sign1; eof2 *= sign2\n",
    "    pc1 *= sign1; pc2 *= sign2\n",
    "    \n",
    "    n_pc1 = pc1/pc1.std(); n_pc2 = pc2/pc2.std()\n",
    "    eindex = (n_pc1 - n_pc2)/np.sqrt(2)\n",
    "    cindex = (n_pc1 + n_pc2)/np.sqrt(2)\n",
    "    e_skew[model]  = skew(eindex); c_skew[model]  = skew(cindex)\n",
    "    # quadratic fit\n",
    "    x = n_pc1; y = n_pc2\n",
    "    #x2= np.arange(min(x),max(x),0.01)\n",
    "    p2 = np.polyfit(x, y, 2)\n",
    "    alpha = p2[0]  \n",
    "    ax[0].scatter(e_skew[model], alpha, s = 20); ax[0].set_xlabel('E-index skewness', fontsize = 14)\n",
    "    ax[1].scatter(c_skew[model], alpha, s = 20, label = model); ax[1].set_xlabel('C-index skewness', fontsize = 14)\n",
    "\n",
    "for axis in ax:\n",
    "    axis.set_ylabel('Alpha', fontsize = 14)\n",
    "    axis.tick_params(axis='both',labelsize=14)\n",
    "ax[1].legend(loc=(1.02,-0.08), fontsize = 14)\n",
    "\n",
    "# linear fit in left plot\n",
    "x = list(e_skew.values()); y = [alphas[model]['piControl'] for model in models]\n",
    "pe = np.polyfit(x, y, 1)\n",
    "x2 = np.arange(min(x), max(x), 0.01)\n",
    "ax[0].plot(x2, np.polyval(pe, x2), color = \"black\")\n",
    "ax[0].text(0.56, 0.05, 'slope = ' + str(np.round(pe[0],2)), fontsize = 14, horizontalalignment='center', verticalalignment='center', transform=ax[0].transAxes)\n",
    "\n",
    "# linear fit in right plot\n",
    "x = list(c_skew.values()); y = [alphas[model]['piControl'] for model in models]\n",
    "pc = np.polyfit(x, y, 1)\n",
    "x2 = np.arange(min(x), max(x), 0.01)\n",
    "ax[1].plot(x2, np.polyval(pc, x2), color = \"black\")\n",
    "ax[1].text(0.56, 0.05, 'slope = ' + str(np.round(pc[0],2)), fontsize = 14, horizontalalignment='center', verticalalignment='center', transform=ax[1].transAxes);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat figure and include also points for all future scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols = 2, figsize = [16,4])\n",
    "color_list = ['Green', 'Lime', 'Blue', 'Red', 'Orange', 'Black', 'Brown', 'Magenta', 'Grey', 'Maroon', 'Cyan']\n",
    "colors = {}  \n",
    "for (i,model) in enumerate(models):\n",
    "    colors[model] = color_list[i]\n",
    "    \n",
    "    if model == 'MCM-UA-1-0': \n",
    "        exp_list = ['piControl','ssp245', 'ssp370', 'ssp585']\n",
    "    else:\n",
    "        exp_list = ['piControl','ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "        \n",
    "    for (k,exp) in enumerate(exp_list):\n",
    "        alpha = alphas[model][exp]\n",
    "        e_skew = e_skewness[model][exp]; c_skew = c_skewness[model][exp];\n",
    "        \n",
    "        ax[0].scatter(e_skew, alpha, s = 20, color = color_list[i]); ax[0].set_xlabel('E-index skewness', fontsize = 14)\n",
    "        if k == 0:\n",
    "            ax[0].scatter(e_skew, alpha, s = 50, color = color_list[i]); ax[0].set_xlabel('E-index skewness', fontsize = 14)\n",
    "            ax[1].scatter(c_skew, alpha, s = 50, label = model, color = color_list[i]); ax[1].set_xlabel('C-index skewness', fontsize = 14)\n",
    "        else:\n",
    "            ax[1].scatter(c_skew, alpha, s = 20, color = color_list[i]); ax[1].set_xlabel('C-index skewness', fontsize = 14)\n",
    "        \n",
    "for axis in ax:\n",
    "    axis.set_ylabel('Alpha', fontsize = 14)\n",
    "    axis.tick_params(axis='both',labelsize=14)\n",
    "ax[1].legend(loc=(1.02,-0.08), fontsize = 14)\n",
    "\n",
    "e_list = []; c_list = []; alpha_list = []\n",
    "for key, value in e_skewness.items():\n",
    "    e_list = np.concatenate([e_list, list(value.values())])\n",
    "for key, value in c_skewness.items():\n",
    "    c_list = np.concatenate([c_list, list(value.values())])\n",
    "for key, value in alphas.items():\n",
    "    alpha_list = np.concatenate([alpha_list, list(value.values())])\n",
    "\n",
    "# linear fit in left plot\n",
    "x = e_list; y = alpha_list\n",
    "pe = np.polyfit(x, y, 1)\n",
    "x2 = np.arange(min(x), max(x), 0.01)\n",
    "ax[0].plot(x2, np.polyval(pe, x2), color = \"black\")\n",
    "ax[0].text(0.56, 0.95, 'slope = ' + str(np.round(pe[0],2)), fontsize = 14, horizontalalignment='center', verticalalignment='center', transform=ax[0].transAxes)\n",
    "\n",
    "# linear fit in right plot\n",
    "x = c_list; y = alpha_list\n",
    "pc = np.polyfit(x, y, 1)\n",
    "x2 = np.arange(min(x), max(x), 0.01)\n",
    "ax[1].plot(x2, np.polyval(pc, x2), '--', color = \"black\")\n",
    "ax[1].text(0.56, 0.95, 'slope = ' + str(np.round(pc[0],2)), fontsize = 14, horizontalalignment='center', verticalalignment='center', transform=ax[1].transAxes);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat analysis above for standard deviation instead of skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols = 2, figsize = [16,4])\n",
    "color_list = ['Green', 'Lime', 'Blue', 'Red', 'Orange', 'Black', 'Brown', 'Magenta', 'Grey', 'Maroon', 'Cyan']\n",
    "colors = {}  \n",
    "for (i,model) in enumerate(models):\n",
    "    colors[model] = color_list[i]\n",
    "    \n",
    "    if model == 'MCM-UA-1-0': \n",
    "        exp_list = ['piControl','ssp245', 'ssp370', 'ssp585']\n",
    "    else:\n",
    "        exp_list = ['piControl','ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "        \n",
    "    for (k,exp) in enumerate(exp_list):\n",
    "        alpha = alphas[model][exp]\n",
    "        e_std = eindex_stds[model][exp]; c_std = cindex_stds[model][exp];\n",
    "        \n",
    "        ax[0].scatter(e_std, alpha, s = 20, color = color_list[i])\n",
    "        if k == 0:\n",
    "            ax[0].scatter(e_std, alpha, s = 50, color = color_list[i]); ax[0].set_xlabel('E-index std', fontsize = 14)\n",
    "            ax[1].scatter(c_std, alpha, s = 50, label = model, color = color_list[i]); ax[1].set_xlabel('C-index std', fontsize = 14)\n",
    "        else:\n",
    "            ax[1].scatter(c_std, alpha, s = 20, color = color_list[i])\n",
    "        \n",
    "for axis in ax:\n",
    "    axis.set_ylabel('Alpha', fontsize = 14)\n",
    "    axis.tick_params(axis='both',labelsize=14)\n",
    "ax[1].legend(loc=(1.02,-0.08), fontsize = 14)\n",
    "\n",
    "e_list = []; c_list = []; alpha_list = []\n",
    "for key, value in eindex_stds.items():\n",
    "    e_list = np.concatenate([e_list, list(value.values())])\n",
    "for key, value in cindex_stds.items():\n",
    "    c_list = np.concatenate([c_list, list(value.values())])\n",
    "for key, value in alphas.items():\n",
    "    alpha_list = np.concatenate([alpha_list, list(value.values())])\n",
    "\n",
    "# linear fit in left plot\n",
    "x = e_list; y = alpha_list\n",
    "pe = np.polyfit(x, y, 1)\n",
    "x2 = np.arange(min(x), max(x), 0.01)\n",
    "ax[0].plot(x2, np.polyval(pe, x2), color = \"black\")\n",
    "ax[0].text(0.56, 0.95, 'slope = ' + str(np.round(pe[0],2)), fontsize = 14, horizontalalignment='center', verticalalignment='center', transform=ax[0].transAxes)\n",
    "\n",
    "# linear fit in right plot\n",
    "x = c_list; y = alpha_list\n",
    "pc = np.polyfit(x, y, 1)\n",
    "x2 = np.arange(min(x), max(x), 0.01)\n",
    "ax[1].plot(x2, np.polyval(pc, x2), '--', color = \"black\")\n",
    "ax[1].text(0.56, 0.95, 'slope = ' + str(np.round(pc[0],2)), fontsize = 14, horizontalalignment='center', verticalalignment='center', transform=ax[1].transAxes);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patterns computed by regressing on C-index and E-index\n",
    "\n",
    "Results obtained using all monthly values, in contrast to Cai et al. who used only DJF means. The plots are currently based on linear regressions with only C-index or only E-index, rather than a bi-linear regression. But it doesn't seem like the results are very sensitive to this choice, when comparing with analyses below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use larger region before regridding, that adds 5 deg to each border:\n",
    "latregion = slice(-15,15); lonregion = slice(140, 280) # = 140 E - 80 W\n",
    "larger_latregion = slice(-20,20); larger_lonregion = slice(135, 285)\n",
    "resolution = 1;\n",
    "ds_out = xr.Dataset({'lon': (['lon'], np.arange(lonregion.start+resolution/2, lonregion.stop+resolution/2, resolution)),\n",
    "                     'lat': (['lat'], np.arange(latregion.start+resolution/2, latregion.stop+resolution/2, resolution))\n",
    "                    }\n",
    "                   )\n",
    "for model in models:\n",
    "    var = model + '_eofs';\n",
    "    eof1 = all_eofs[var].sel(mode=0)\n",
    "    eof2 = all_eofs[var].sel(mode=1)\n",
    "\n",
    "    var2 = model + '_pcs'\n",
    "    pc1 = all_pcs[var2].sel(mode=0)\n",
    "    pc2 = all_pcs[var2].sel(mode=1)\n",
    "    \n",
    "    # make consistent signs:\n",
    "    sign1 = eof_sign(eof1); sign2 = eof_sign(eof2)\n",
    "    eof1 *= sign1; eof2 *= sign2\n",
    "    pc1 *= sign1; pc2 *= sign2\n",
    "    \n",
    "    n_pc1 = pc1/pc1.std(); n_pc2 = pc2/pc2.std()\n",
    "    eindex = (n_pc1 - n_pc2)/np.sqrt(2)\n",
    "    cindex = (n_pc1 + n_pc2)/np.sqrt(2)\n",
    "    \n",
    "    # load piControl data\n",
    "    member = picontrol_member(model)\n",
    "    cat = col.search(experiment_id = 'piControl', source_id = model, variable_id='ts', table_id='Amon', member_id = member)\n",
    "    dset_dict = cat.to_dataset_dict(zarr_kwargs={'consolidated': True}, cdf_kwargs={'chunks': {}})\n",
    "    for key in dset_dict.keys():\n",
    "        ds = dset_dict[key].sel(member_id = member)\n",
    "    if model == 'MCM-UA-1-0':\n",
    "        ds = ds.rename({'longitude': 'lon','latitude': 'lat'})\n",
    "    regional_data = ds.ts.sel(lat = larger_latregion, lon = larger_lonregion)\n",
    "    regridder = xe.Regridder(regional_data, ds_out, 'bilinear', reuse_weights = True)\n",
    "    regridded_data = regridder(regional_data)\n",
    "\n",
    "    # linear detrending for first 500 years:\n",
    "    ds_detr = xr.apply_ufunc(detrend, regridded_data[:500*12], kwargs={'axis': 0}, dask = 'allowed')\n",
    "\n",
    "    # deseasonalise\n",
    "    ts_clim = ds_detr.groupby('time.month').mean(dim='time')\n",
    "    ts_anom = ds_detr.groupby('time.month') - ts_clim\n",
    "    \n",
    "    # do regressions\n",
    "    dataset = ts_anom.stack(grid_cells=('lon', 'lat'))\n",
    "    p_e = np.polyfit(eindex.dropna(dim = 'time'), dataset, deg=1); p_c = np.polyfit(cindex.dropna(dim = 'time'), dataset, deg=1);\n",
    "    e_pattern_da = xr.DataArray(p_e[0], coords = {'grid_cells': dataset.grid_cells}, dims = ['grid_cells'])\n",
    "    c_pattern_da = xr.DataArray(p_c[0], coords = {'grid_cells': dataset.grid_cells}, dims = ['grid_cells'])\n",
    "    e_pattern = e_pattern_da.unstack('grid_cells'); c_pattern = c_pattern_da.unstack('grid_cells'); \n",
    "    #pattern_ds = pattern_da.to_dataset(name = 'eindex_pattern').unstack('grid_cells')\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols = 2, figsize = [20,3], subplot_kw={'projection': data_crs})\n",
    "    \n",
    "    cs0 = ax[0].contourf(ts_anom.lon, ts_anom.lat, (e_pattern).transpose(), np.arange(-maxval,maxval+step,step), cmap = 'bwr',extend='both', transform=ccrs.PlateCarree())\n",
    "    cs1 = ax[1].contourf(ts_anom.lon, ts_anom.lat, (c_pattern).transpose(), np.arange(-maxval,maxval+step,step), cmap = 'bwr',extend='both', transform=ccrs.PlateCarree())\n",
    "    for i in [0,1]:\n",
    "        ax[i].coastlines(color='gray')\n",
    "    cbar = fig.colorbar(cs1, ax = ax.ravel().tolist(), orientation=\"vertical\")\n",
    "    cbar.set_label('Temperature anomaly', fontsize = 14)\n",
    "    cbar.ax.tick_params(labelsize = 14)\n",
    "    \n",
    "    ax[0].set_title(model + ' EP-ENSO pattern')\n",
    "    ax[1].set_title(model + ' CP-ENSO pattern')\n",
    "    \n",
    "    plt.setp(ax, xticks = np.arange(150, 280, 30)-180, xticklabels = ['150°E', '180°W', '150°W', '120°W', '90°W'])\n",
    "    plt.setp(ax, yticks = [-10, 0, 10], yticklabels = ['10°S', '0', '10°N'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative way of finding patterns associated with C-index and E-index\n",
    "\n",
    "Using all monthly data, patterns can be defined such that:\n",
    "\n",
    "EOF1 * PC1 + EOF2 * PC2   =   C-index * CP-ENSO pattern + E-index * EP-ENSO pattern\n",
    "\n",
    "Results of this should be very close (or equal?) to a bi-linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "maxval = 1.2; step = 0.1\n",
    "data_crs = ccrs.PlateCarree(central_longitude=180.0)\n",
    "\n",
    "for model in models:\n",
    "    var = model + '_eofs'; var_frac = model + '_variance_fractions'\n",
    "    eof1 = all_eofs[var].sel(mode=0); var_frac1 = all_variance_fractions[var_frac].sel(mode=0).values\n",
    "    eof2 = all_eofs[var].sel(mode=1); var_frac2 = all_variance_fractions[var_frac].sel(mode=1).values\n",
    "    \n",
    "    var2 = model + '_pcs'\n",
    "    pc1 = all_pcs[var2].sel(mode=0)\n",
    "    pc2 = all_pcs[var2].sel(mode=1)\n",
    "    \n",
    "    # make consistent signs:\n",
    "    sign1 = eof_sign(eof1); sign2 = eof_sign(eof2)\n",
    "    eof1 *= sign1; eof2 *= sign2\n",
    "    pc1 *= sign1; pc2 *= sign2\n",
    "    \n",
    "    ep_enso = np.sqrt(2)/2*(eof1*pc1.std() - eof2*pc2.std())\n",
    "    cp_enso = np.sqrt(2)/2*(eof1*pc1.std() + eof2*pc2.std())\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols = 2, figsize = [20,3], subplot_kw={'projection': data_crs})\n",
    "    \n",
    "    cs0 = ax[0].contourf(all_eofs.lon, all_eofs.lat, (ep_enso).transpose(), np.arange(-maxval,maxval+step,step), cmap = 'bwr',extend='both', transform=ccrs.PlateCarree())\n",
    "    cs1 = ax[1].contourf(all_eofs.lon, all_eofs.lat, (cp_enso).transpose(), np.arange(-maxval,maxval+step,step), cmap = 'bwr',extend='both', transform=ccrs.PlateCarree())\n",
    "    for i in [0,1]:\n",
    "        ax[i].coastlines(color='gray')\n",
    "    cbar = fig.colorbar(cs1, ax = ax.ravel().tolist(), orientation=\"vertical\")\n",
    "    cbar.set_label('Temperature anomaly', fontsize = 14)\n",
    "    cbar.ax.tick_params(labelsize = 14)\n",
    "    \n",
    "    ax[0].set_title(model + ' EP-ENSO pattern')\n",
    "    ax[1].set_title(model + ' CP-ENSO pattern')\n",
    "    #ax[1].text(alphas[model]['piControl'])\n",
    "    ax[1].text(1.05, 0.5, r'$\\alpha = $' + str(np.round(alphas[model]['piControl'],3)), fontsize = 16, horizontalalignment='center', verticalalignment='center', transform=ax[1].transAxes, rotation = 90);\n",
    "    \n",
    "    plt.setp(ax, xticks = np.arange(150, 280, 30)-180, xticklabels = ['150°E', '180°W', '150°W', '120°W', '90°W'])\n",
    "    plt.setp(ax, yticks = [-10, 0, 10], yticklabels = ['10°S', '0', '10°N'])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMIP6 2019.10a",
   "language": "python",
   "name": "cmip6-201910a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
